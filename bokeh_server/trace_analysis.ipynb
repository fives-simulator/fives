{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding a Bokeh server in a Notebook\n",
    "\n",
    "This notebook shows how a Bokeh server application can be embedded inside a Jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColumnDataSource, Slider\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.themes import Theme\n",
    "from bokeh.io import show, output_notebook\n",
    "\n",
    "from bokeh.sampledata.sea_surface_temperature import sea_surface_temperature\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT IO TRACES AND CREATE TWO DATAFRAMES\n",
    "\n",
    "io_traces = None\n",
    "with open(\"io_operations.yml\", \"r\", encoding=\"utf-8\") as traces:\n",
    "    io_traces = yaml.load(traces, Loader=yaml.SafeLoader)\n",
    "\n",
    "job_columns = [\n",
    "    \"job_id\",\n",
    "    \"job_uid\"\n",
    "    \"job_status\", \n",
    "    \"job_submit_ts\", \n",
    "    \"job_end_ts\", \n",
    "    \"job_duration\",\n",
    "    \"origin_runtime\",\n",
    "    \"origin_read_bytes\",\n",
    "    \"origin_written_bytes\",\n",
    "    \"origin_core_used\",\n",
    "    \"origin_mpi_procs\",\n",
    "    \"job_sleep_time\",\n",
    "]\n",
    "\n",
    "# Not all columns are used by every type of action...\n",
    "action_columns = [\n",
    "    \"act_name\",\n",
    "    \"act_type\",\n",
    "    \"act_status\",\n",
    "    \"act_start_ts\",\n",
    "    \"act_end_ts\",\n",
    "    \"act_duration\",\n",
    "    \"src_storage_service\",\n",
    "    \"src_storage_server\",\n",
    "    \"src_storage_disk\",\n",
    "    \"src_file_path\",\n",
    "    \"src_file_name\",\n",
    "    \"src_file_size_bytes\",\n",
    "    \"dst_storage_service\",\n",
    "    \"dst_storage_server\",\n",
    "    \"dst_storage_disk\",\n",
    "    \"dst_file_path\",\n",
    "    \"dst_file_name\",\n",
    "    \"dst_file_size_bytes\",\n",
    "    \"parent_job_id\",\n",
    "]\n",
    "\n",
    "# DATAFRAME WITH JOBS ONLY\n",
    "jobs = pd.DataFrame(io_traces, columns=job_columns)\n",
    "\n",
    "\n",
    "\n",
    "# Merge all actions into a second DataFrame, with new \"parent_job_id\" field associated to each one.\n",
    "action_list = []\n",
    "for trace in io_traces:\n",
    "    local_actions = trace[\"job_actions\"]\n",
    "    for l_act in local_actions:\n",
    "        l_act[\"parent_job_id\"] = trace[\"job_id\"]\n",
    "        if not \"src_storage_service\" in l_act:\n",
    "            l_act[\"src_storage_service\"] = \"NA\"\n",
    "            l_act[\"src_storage_server\"] = \"NA\"\n",
    "            l_act[\"src_storage_disk\"] = \"NA\"\n",
    "            l_act[\"src_file_path\"] = \"NA\"\n",
    "            l_act[\"src_file_name\"] = \"NA\"\n",
    "            l_act[\"src_file_size_bytes\"] = 0\n",
    "        if not \"dst_storage_service\" in l_act:\n",
    "            l_act[\"dst_storage_service\"] = \"NA\"\n",
    "            l_act[\"dst_storage_server\"] = \"NA\"\n",
    "            l_act[\"dst_storage_disk\"] = \"NA\"\n",
    "            l_act[\"dst_file_path\"] = \"NA\"\n",
    "            l_act[\"dst_file_name\"] = \"NA\"\n",
    "            l_act[\"dst_file_size_bytes\"] = 0\n",
    "        action_list.append(l_act)\n",
    "        \n",
    "# DATAFRAME WITH ACTIONS ONLY\n",
    "actions = pd.DataFrame(action_list, columns=action_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = jobs.sort_values(\"job_submit_ts\")\n",
    "jobs[\"job_submit_td\"] = jobs[\"job_submit_ts\"].apply(pd.to_timedelta, unit=\"s\")\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = actions.sort_values(\"act_start_ts\")\n",
    "\n",
    "# Create Timedelta columns from timestamp, in order to display data with valid date range in following plots\n",
    "actions[\"act_start_td\"] = actions[\"act_start_ts\"].apply(pd.to_timedelta, unit=\"s\")\n",
    "actions[\"act_end_td\"] = actions[\"act_end_ts\"].apply(pd.to_timedelta, unit=\"s\")\n",
    "\n",
    "print(f\"# First action registered on {dt.datetime.fromtimestamp(actions['act_start_ts'].min())}\")\n",
    "print(f\"# Last action ends on {dt.datetime.fromtimestamp(actions['act_end_ts'].max())}\")\n",
    "\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "from bokeh.models import ColumnDataSource, RangeTool, DatetimeTickFormatter, NumeralTickFormatter\n",
    "from bokeh.transform import factor_cmap, factor_mark\n",
    "\n",
    "\n",
    "VERBOSE_DT_FORMATTER = DatetimeTickFormatter(days='%d/%m', hours=\"%d/%m - %Hh\", hourmin='%H:%M', minutes = '%H:%M')\n",
    "BYTE_FORMATTER = NumeralTickFormatter(format='0.0b')\n",
    "\n",
    "\n",
    "def bkapp(doc):\n",
    "    df = actions.copy()\n",
    "    source = ColumnDataSource(data=df)\n",
    "\n",
    "    DT_X_RANGE = (df[\"act_start_td\"].min(), df[\"act_start_td\"].max())\n",
    "    \n",
    "    # TIMELINE WITH VARIOUS METRICS\n",
    "    p = figure(\n",
    "        title=\"R/W Volume\", \n",
    "        height=300, \n",
    "        width=800, \n",
    "        tools=[\"xpan\", \"save\", \"reset\", \"box_zoom\", \"pan\", \"zoom_out\"],\n",
    "        x_axis_location=\"above\",\n",
    "        background_fill_color=\"#efefef\", \n",
    "        x_range=DT_X_RANGE\n",
    "    )\n",
    "    \n",
    "    p.vbar(x='act_start_td', top='src_file_size_bytes', source=source , width=0.9)\n",
    "    \n",
    "    # p.line('act_start_td', 'src_file_size_bytes', source=source, line_color=(0, 128, 255, 0.5), line_width=2)\n",
    "    # p.line('act_start_td', 'dst_file_size_bytes', source=source, line_color=(128, 255, 0, 0.5), line_width=2)\n",
    "    p.yaxis.axis_label = 'Byte size of file'\n",
    "    p.xaxis.formatter = VERBOSE_DT_FORMATTER\n",
    "    p.yaxis.formatter = BYTE_FORMATTER\n",
    "    \n",
    "\n",
    "    TYPES = [\"FILECOPY\", \"FILEREAD\", \"COMPUTE\", \"FILEWRITE\", \"FILEDELETE\"]\n",
    "    #TYPES = sorted(df.act_type.unique())\n",
    "    p2 = figure(\n",
    "        title=\"ActionTypes\", \n",
    "        height=300, \n",
    "        width=800, \n",
    "        tools=[\"xpan\", \"save\", \"reset\", \"box_zoom\", \"pan\", \"zoom_out\"],\n",
    "        x_axis_location=\"above\",\n",
    "        background_fill_color=\"#efefef\", \n",
    "        x_range=p.x_range, \n",
    "        y_range=TYPES[::-1]\n",
    "    )\n",
    "\n",
    "    MARKERS = ['hex', 'circle_x', 'triangle', 'plus', 'diamond']\n",
    "    p2.scatter(\"act_start_td\", \"act_type\", source=source,\n",
    "          legend_group=\"act_type\", fill_alpha=0.3, size=12,\n",
    "          marker=factor_mark('act_type', MARKERS, TYPES),\n",
    "          color=factor_cmap('act_type', 'Category10_5', TYPES))\n",
    "    p2.yaxis.axis_label = 'Action Type'\n",
    "    p2.xaxis.formatter = VERBOSE_DT_FORMATTER\n",
    "    \n",
    "    select = figure(title=\"Range selection plot\",\n",
    "                height=100, width=800, y_range=p.y_range, y_axis_type=None,\n",
    "                tools=\"\", toolbar_location=None, background_fill_color=\"#efefef\")\n",
    "    \n",
    "    range_tool = RangeTool(x_range=p.x_range)\n",
    "    range_tool.overlay.fill_color = \"navy\"\n",
    "    range_tool.overlay.fill_alpha = 0.1\n",
    "\n",
    "    select.line('act_start_td', 'src_file_size_bytes', source=source, line_color=(255, 128, 0, 0.5))\n",
    "    select.line('act_start_td', 'dst_file_size_bytes', source=source, line_color=(128, 255, 0, 0.5))\n",
    "    select.ygrid.grid_line_color = None\n",
    "    select.xaxis.formatter = VERBOSE_DT_FORMATTER\n",
    "    select.yaxis.formatter = BYTE_FORMATTER\n",
    "    select.add_tools(range_tool)\n",
    "    select.toolbar.active_multi = range_tool\n",
    "    \n",
    "    def callback(attr, old, new):\n",
    "        if new == 0:\n",
    "            data = df\n",
    "        else:\n",
    "            data = df\n",
    "        source.data = ColumnDataSource.from_df(data)\n",
    "\n",
    "    doc.add_root(column(p, p2, select))\n",
    "\n",
    "    doc.theme = Theme(json=yaml.load(\"\"\"\n",
    "        attrs:\n",
    "            figure:\n",
    "                background_fill_color: \"#DDDDDD\"\n",
    "                outline_line_color: white\n",
    "                toolbar_location: above\n",
    "                height: 700\n",
    "                width: 1200\n",
    "            Grid:\n",
    "                grid_line_dash: [6, 4]\n",
    "                grid_line_color: white\n",
    "    \"\"\", Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can display our application using ``show``, which will automatically create an ``Application`` that wraps ``bkapp`` using ``FunctionHandler``. The end result is that the Bokeh server will call ``bkapp`` to build new documents for every new sessions that is opened.\n",
    "\n",
    "**Note**: If the current notebook is not displayed at the default URL, you must update the `notebook_url` parameter in the comment below to match, and pass it to `show`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(bkapp) # notebook_url=\"http://localhost:8888\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
