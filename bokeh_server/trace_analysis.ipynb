{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding a Bokeh server in a Notebook\n",
    "\n",
    "This notebook shows how a Bokeh server application can be embedded inside a Jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import (ColumnDataSource, Slider, LabelSet, CategoricalColorMapper, DataTable, HoverTool, IntEditor,\n",
    "                          NumberEditor, NumberFormatter, SelectEditor,\n",
    "                          StringEditor, StringFormatter, TableColumn)\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.themes import Theme\n",
    "from bokeh.palettes import Spectral4, viridis\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.transform import jitter\n",
    "import colorcet as cc\n",
    "\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT IO TRACES AND CREATE TWO DATAFRAMES\n",
    "\n",
    "io_traces = None\n",
    "with open(\"io_operations.yml\", \"r\", encoding=\"utf-8\") as traces:\n",
    "    io_traces = yaml.load(traces, Loader=yaml.SafeLoader)\n",
    "\n",
    "job_columns = [\n",
    "    \"job_id\",\n",
    "    \"job_uid\"\n",
    "    \"job_status\", \n",
    "    \"job_submit_ts\", \n",
    "    \"job_end_ts\", \n",
    "    \"job_duration\",\n",
    "    \"origin_runtime\",\n",
    "    \"origin_read_bytes\",\n",
    "    \"origin_written_bytes\",\n",
    "    \"origin_core_used\",\n",
    "    \"origin_mpi_procs\",\n",
    "    \"job_sleep_time\",\n",
    "]\n",
    "\n",
    "# Not all columns are used by every type of action...\n",
    "action_columns = [\n",
    "    \"act_name\",\n",
    "    \"act_type\",\n",
    "    \"act_status\",\n",
    "    \"act_start_ts\",\n",
    "    \"act_end_ts\",\n",
    "    \"act_duration\",\n",
    "    \"src_storage_service\",\n",
    "    \"src_storage_server\",\n",
    "    \"src_storage_disk\",\n",
    "    \"src_file_path\",\n",
    "    \"src_file_name\",\n",
    "    \"src_file_size_bytes\",\n",
    "    \"dst_storage_service\",\n",
    "    \"dst_storage_server\",\n",
    "    \"dst_storage_disk\",\n",
    "    \"dst_file_path\",\n",
    "    \"dst_file_name\",\n",
    "    \"dst_file_size_bytes\",\n",
    "    \"parent_job_id\",\n",
    "]\n",
    "\n",
    "# DATAFRAME WITH JOBS ONLY\n",
    "jobs = pd.DataFrame(io_traces, columns=job_columns)\n",
    "\n",
    "\n",
    "\n",
    "# Merge all actions into a second DataFrame, with new \"parent_job_id\" field associated to each one.\n",
    "action_list = []\n",
    "for trace in io_traces:\n",
    "    local_actions = trace[\"job_actions\"]\n",
    "    for l_act in local_actions:\n",
    "        l_act[\"parent_job_id\"] = trace[\"job_id\"]\n",
    "        if not \"src_storage_service\" in l_act:\n",
    "            l_act[\"src_storage_service\"] = \"NA\"\n",
    "            l_act[\"src_storage_server\"] = \"NA\"\n",
    "            l_act[\"src_storage_disk\"] = \"NA\"\n",
    "            l_act[\"src_file_path\"] = \"NA\"\n",
    "            l_act[\"src_file_name\"] = \"NA\"\n",
    "            l_act[\"src_file_size_bytes\"] = 0\n",
    "        if not \"dst_storage_service\" in l_act:\n",
    "            l_act[\"dst_storage_service\"] = \"NA\"\n",
    "            l_act[\"dst_storage_server\"] = \"NA\"\n",
    "            l_act[\"dst_storage_disk\"] = \"NA\"\n",
    "            l_act[\"dst_file_path\"] = \"NA\"\n",
    "            l_act[\"dst_file_name\"] = \"NA\"\n",
    "            l_act[\"dst_file_size_bytes\"] = 0\n",
    "        action_list.append(l_act)\n",
    "        \n",
    "# DATAFRAME WITH ACTIONS ONLY\n",
    "actions = pd.DataFrame(action_list, columns=action_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = jobs.sort_values(\"job_submit_ts\")\n",
    "jobs[\"job_submit_td\"] = jobs[\"job_submit_ts\"].apply(pd.to_timedelta, unit=\"s\")\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = actions.sort_values(\"act_start_ts\")\n",
    "\n",
    "# Create Timedelta columns from timestamp, in order to display data with valid date range in following plots\n",
    "actions[\"act_start_td\"] = actions[\"act_start_ts\"].apply(pd.to_timedelta, unit=\"s\")\n",
    "actions[\"act_end_td\"] = actions[\"act_end_ts\"].apply(pd.to_timedelta, unit=\"s\")\n",
    "\n",
    "print(f\"# First action registered on {dt.datetime.fromtimestamp(actions['act_start_ts'].min())}\")\n",
    "print(f\"# Last action ends on {dt.datetime.fromtimestamp(actions['act_end_ts'].max())}\")\n",
    "\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT STORAGE SERVICE ORIENTED IO TRACES AND CREATE TWO DATAFRAMES\n",
    "\n",
    "io_traces_storage_service = None\n",
    "with open(\"storage_service_operations.yml\", \"r\", encoding=\"utf-8\") as traces:\n",
    "    io_traces_storage_service = yaml.load(traces, Loader=yaml.SafeLoader)\n",
    "    \n",
    "ss_io_columns = [\n",
    "    \"ts\",\n",
    "    \"action_type\",\n",
    "    \"action_name\",\n",
    "    \"action_job\",\n",
    "    \"storage_service\",\n",
    "    \"disk\",\n",
    "    \"volume_change_bytes\",\n",
    "    \"total_allocation_server\",\n",
    "    \"total_used_volume_bytes_server\",\n",
    "    \"total_allocation_disk\",\n",
    "    \"total_used_volume_bytes_disk\",\n",
    "]\n",
    "\n",
    "actions_detail = pd.DataFrame(io_traces_storage_service, columns=ss_io_columns)\n",
    "actions_detail = actions_detail.sort_values(\"ts\")\n",
    "actions_detail[\"ts\"] = actions_detail[\"ts\"].apply(pd.to_timedelta, unit=\"s\")\n",
    "#actions_detail[\"action_job\"] = actions_detail[\"action_job\"].astype('object')\n",
    "actions_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_UIDS = list(set(actions_detail[\"action_job\"].astype(\"string\").tolist()))\n",
    "print(f\"JOBS UIDS (unique) : {JOB_UIDS}\")\n",
    "\n",
    "JOB_UIDS_COLOR = [cc.glasbey_dark[i] for i in range(len(JOB_UIDS))]\n",
    "print(JOB_UIDS_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mulitple sub-dataframes, one for each storage service in use in our data\n",
    "details_by_storageservice = actions_detail.groupby('storage_service', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a dataframe for each type of action\n",
    "\n",
    "copy_actions_detail = actions_detail[actions_detail[\"action_type\"] == \"FILECOPY\"]\n",
    "write_actions_detail = actions_detail[actions_detail[\"action_type\"] == \"FILEWRITE\"]\n",
    "delete_actions_detail = actions_detail[actions_detail[\"action_type\"] == \"FILEDELETE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "from bokeh.models import ColumnDataSource, RangeTool, DatetimeTickFormatter, NumeralTickFormatter\n",
    "from bokeh.transform import factor_cmap, factor_mark\n",
    "\n",
    "\n",
    "VERBOSE_DT_FORMATTER = DatetimeTickFormatter(days='%d/%m', hours=\"%d/%m - %Hh\", hourmin='%H:%M', minutes = '%H:%M')\n",
    "BYTE_FORMATTER = NumeralTickFormatter(format='0.0b')\n",
    "TYPES = [\"FILECOPY\", \"FILEREAD\", \"COMPUTE\", \"FILEWRITE\", \"FILEDELETE\"]\n",
    "IO_TYPES = [\"FILECOPY\", \"FILEREAD\", \"FILEWRITE\", \"FILEDELETE\"]\n",
    "IO_TYPES_NO_READ = [\"FILECOPY\", \"FILEWRITE\", \"FILEDELETE\"]\n",
    "MARKERS_ACTION_TYPE = ['circle_y', 'circle_cross', 'circle_x']\n",
    "\n",
    "\n",
    "def bkapp(doc):\n",
    "    \n",
    "    # General DataFrame\n",
    "    df = actions.copy()\n",
    "    source = ColumnDataSource(data=df)\n",
    "    \n",
    "    # Details DataFrame\n",
    "    df_actions_details = actions_detail.copy()\n",
    "    df_details_source  = ColumnDataSource(data=df_actions_details)\n",
    "    \n",
    "    df_copy_details = copy_actions_detail.copy()\n",
    "    df_copy_source  = ColumnDataSource(data=df_copy_details)\n",
    "    \n",
    "    df_write_details = write_actions_detail.copy()\n",
    "    df_write_source  = ColumnDataSource(data=df_write_details)\n",
    "    \n",
    "    df_delete_details = delete_actions_detail.copy()\n",
    "    df_delete_source  = ColumnDataSource(data=df_delete_details)\n",
    "    \n",
    "    DT_X_RANGE = (df[\"act_start_td\"].min() - dt.timedelta(seconds=10000), \n",
    "                  df[\"act_start_td\"].max() + dt.timedelta(seconds=10000))\n",
    "\n",
    "    \n",
    "    # TIMELINE WITH VARIOUS METRICS\n",
    "    p = figure(\n",
    "        title=\"Cumulative R/W Volume\", \n",
    "        height=300, \n",
    "        width=950, \n",
    "        tools=[\"xpan\", \"save\", \"reset\", \"box_zoom\", \"pan\", \"zoom_out\"],\n",
    "        x_axis_location=\"above\",\n",
    "        background_fill_color=\"#efefef\", \n",
    "        x_range=DT_X_RANGE\n",
    "    )\n",
    "    \n",
    "    # p.vbar(x='act_start_td', top='src_file_size_bytes', source=source , width=0.9)\n",
    "\n",
    "    write_cumsum = df_write_details[\"volume_change_bytes\"].cumsum()\n",
    "    p.varea(x=df_write_details[\"ts\"], \n",
    "            y1=np.zeros(write_cumsum.shape[0]), \n",
    "            y2=write_cumsum, \n",
    "            alpha=0.8, \n",
    "            color=(0, 255, 0, 0.5),\n",
    "            legend_label=\"WRITE\")\n",
    "    \n",
    "    copy_cumsum = df_copy_details[\"volume_change_bytes\"].cumsum()\n",
    "    p.varea(x=df_copy_details[\"ts\"], \n",
    "            y1=np.zeros(copy_cumsum.shape[0]), \n",
    "            y2=copy_cumsum, \n",
    "            alpha=0.8, \n",
    "            color=(0, 0, 255, 0.5),\n",
    "            legend_label=\"COPY\")\n",
    "        \n",
    "    delete_cumsum = delete_actions_detail[\"volume_change_bytes\"].cumsum()\n",
    "    p.varea(x=df_delete_details[\"ts\"], \n",
    "            y1=np.zeros(delete_cumsum.shape[0]), \n",
    "            y2=delete_cumsum, \n",
    "            alpha=0.8, \n",
    "            color=(255, 0, 0, 0.5),\n",
    "            legend_label=\"DELETE\")\n",
    "    \n",
    "    \n",
    "    p.legend.click_policy=\"hide\"\n",
    "    \n",
    "    #p.varea_stack(stackers=TYPES, x=\"ts\")\n",
    "    \n",
    "    \n",
    "    # p.line('act_start_td', 'src_file_size_bytes', source=source, line_color=(0, 128, 255, 0.5), line_width=2)\n",
    "    # p.line('act_start_td', 'dst_file_size_bytes', source=source, line_color=(128, 255, 0, 0.5), line_width=2)\n",
    "    p.yaxis.axis_label = 'Byte size of file'\n",
    "    p.xaxis.formatter = VERBOSE_DT_FORMATTER\n",
    "    p.yaxis.formatter = BYTE_FORMATTER\n",
    "    \n",
    "    \n",
    "    p2 = figure(\n",
    "        title=\"ActionTypes\", \n",
    "        height=300, \n",
    "        width=950, \n",
    "        tools=[\"xpan\", \"save\", \"reset\", \"box_zoom\", \"pan\", \"zoom_out\", \"hover\"],\n",
    "        x_axis_location=\"above\",\n",
    "        background_fill_color=\"#efefef\", \n",
    "        x_range=p.x_range, \n",
    "        # y_range=TYPES[::-1]\n",
    "    )\n",
    "    p2.hover.tooltips = [\n",
    "        (\"Action Type\", \"@action_type\"),\n",
    "        (\"Bytes Copied/Written/Deleted\", \"@volume_change_bytes\"), \n",
    "        (\"Target Server\", \"@storage_service\"),\n",
    "        (\"Target Disk\", \"@disk\")\n",
    "    ]\n",
    "    \n",
    "    p2.yaxis.axis_label = 'Bytes'\n",
    "    p2.xaxis.formatter = VERBOSE_DT_FORMATTER\n",
    "    p2.yaxis.formatter = BYTE_FORMATTER\n",
    "    \n",
    "    \n",
    "    ## JOB_UID INDEXED\n",
    "    p2.scatter(x=\"ts\", y=\"volume_change_bytes\", \n",
    "               source=df_details_source,\n",
    "               legend_group=\"action_job\", \n",
    "               fill_alpha=0.4, \n",
    "               size=12,\n",
    "               marker=factor_mark('action_type', MARKERS_ACTION_TYPE, IO_TYPES_NO_READ),\n",
    "               color=factor_cmap(\"action_job\", cc.glasbey_dark, JOB_UIDS))\n",
    "    \n",
    "    \n",
    "    ## STORAGE SERVICE INDEXED\n",
    "    STORAGE_SERVICES = df_actions_details[\"storage_service\"].unique()\n",
    "    \n",
    "    for service, color in zip(STORAGE_SERVICES, Spectral4):\n",
    "        p2.line(x=\"ts\", \n",
    "                y=\"total_used_volume_bytes_server\", \n",
    "                source=df_actions_details[df_actions_details[\"storage_service\"] == service], \n",
    "                line_width=2,\n",
    "                color=color, \n",
    "                alpha=0.8, \n",
    "                muted_color=color, \n",
    "                muted_alpha=0.1, \n",
    "                legend_label=service)\n",
    "        \n",
    "    p2.legend.click_policy=\"mute\"\n",
    "    \n",
    "    \"\"\"\n",
    "    labels = LabelSet(x=\"ts\", y=\"volume_change_bytes\", text=\"symbol\", y_offset=20,\n",
    "                  text_font_size=\"11px\", text_color=\"#ffffff\",\n",
    "                  source=df_details_source, text_align='center')\n",
    "    p2.add_layout(labels)\n",
    "    \"\"\"\n",
    "    \n",
    "    action_name = sorted(df_actions_details[\"action_name\"].unique())\n",
    "    \n",
    "    columns = [\n",
    "        TableColumn(field=\"action_name\", title=\"Action Name\",\n",
    "                editor=SelectEditor(options=action_name),\n",
    "                formatter=StringFormatter(font_style=\"bold\"))\n",
    "    ]\n",
    "    \n",
    "    \"\"\"\n",
    "        TableColumn(field=\"model\", title=\"Model\",\n",
    "                editor=StringEditor(completions=models)),\n",
    "        TableColumn(field=\"displ\", title=\"Displacement\",\n",
    "                editor=NumberEditor(step=0.1), formatter=NumberFormatter(format=\"0.0\")),\n",
    "        TableColumn(field=\"year\", title=\"Year\", editor=IntEditor()),\n",
    "        TableColumn(field=\"cyl\", title=\"Cylinders\", editor=IntEditor()),\n",
    "        TableColumn(field=\"trans\", title=\"Transmission\",\n",
    "                editor=SelectEditor(options=transmissions)),\n",
    "        TableColumn(field=\"drv\", title=\"Drive\", editor=SelectEditor(options=drives)),\n",
    "        TableColumn(field=\"class\", title=\"Class\", editor=SelectEditor(options=classes)),\n",
    "        TableColumn(field=\"cty\", title=\"City MPG\", editor=IntEditor()),\n",
    "        TableColumn(field=\"hwy\", title=\"Highway MPG\", editor=IntEditor()),\n",
    "    \"\"\"\n",
    "    data_table = DataTable(source=df_details_source, columns=columns, editable=True, width=950,\n",
    "                       index_position=-1, index_header=\"row index\", index_width=60)\n",
    "    \n",
    "    \n",
    "    # RANGE SELECTION    \n",
    "    select = figure(title=\"Range selection plot\",\n",
    "                height=100, width=950, y_range=p.y_range, y_axis_type=None,\n",
    "                tools=\"\", toolbar_location=None, background_fill_color=\"#efefef\")\n",
    "    \n",
    "    range_tool = RangeTool(x_range=p.x_range)\n",
    "    range_tool.overlay.fill_color = \"navy\"\n",
    "    range_tool.overlay.fill_alpha = 0.1\n",
    "\n",
    "    select.line('act_start_td', 'src_file_size_bytes', source=source, line_color=(255, 128, 0, 0.5))\n",
    "    select.line('act_start_td', 'dst_file_size_bytes', source=source, line_color=(128, 255, 0, 0.5))\n",
    "    select.ygrid.grid_line_color = None\n",
    "    select.xaxis.formatter = VERBOSE_DT_FORMATTER\n",
    "    select.yaxis.formatter = BYTE_FORMATTER\n",
    "    select.add_tools(range_tool)\n",
    "    select.toolbar.active_multi = range_tool\n",
    "    \n",
    "    def callback(attr, old, new):\n",
    "        if new == 0:\n",
    "            data = df\n",
    "        else:\n",
    "            data = df\n",
    "        source.data = ColumnDataSource.from_df(data)\n",
    "\n",
    "    doc.add_root(column(p, p2, select, data_table))\n",
    "\n",
    "    doc.theme = Theme(json=yaml.load(\"\"\"\n",
    "        attrs:\n",
    "            figure:\n",
    "                background_fill_color: \"#DDDDDD\"\n",
    "                outline_line_color: white\n",
    "                toolbar_location: above\n",
    "                height: 700\n",
    "                width: 1200\n",
    "            Grid:\n",
    "                grid_line_dash: [6, 4]\n",
    "                grid_line_color: white\n",
    "    \"\"\", Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can display our application using ``show``, which will automatically create an ``Application`` that wraps ``bkapp`` using ``FunctionHandler``. The end result is that the Bokeh server will call ``bkapp`` to build new documents for every new sessions that is opened.\n",
    "\n",
    "**Note**: If the current notebook is not displayed at the default URL, you must update the `notebook_url` parameter in the comment below to match, and pass it to `show`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show(bkapp) # notebook_url=\"http://localhost:8888\" "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
