{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20cdc434-4b8f-4fcd-a8be-566b77de7236",
   "metadata": {},
   "source": [
    "# Analysis notebook for Fives simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "336518dc-e1d3-4170-888f-851034040d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "# Changes only when calibration dataset is modified\n",
    "CALIBRATION_MONTH = 11 # Month used for calibration (eg. 11 for november)\n",
    "CALIB_CAT = 1          # Job category used during calibration\n",
    "VALID_CAT = 1          # Job category used after calibration, using the calibrated configuration \n",
    "                       # (it is possible to simulate, eg. cat. 0 jobs with a cat. 1 calibrated file)\n",
    "\n",
    "# Changes with each calibration, depending on time of calibration and results\n",
    "ID = 955  # Update with your own here\n",
    "EXP_UID = f\"para{ID}\" # used inside filenames\n",
    "RES_DIR = f\"months_{ID}\" # In the directory containing this notebook, we'll be looking for Fives output files inside this sub directory.\n",
    "\n",
    "# Corresponds to static overheads added to batches of I/O actions during the simulation, \n",
    "# to compensate for the lack of metadata operations and other related phenomemon. Values \n",
    "# can be obtained from the calibrated configuration files of Fives.\n",
    "overhead_read = 2\n",
    "overhead_write = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e896cb-198c-4e4a-97cd-2f6d89816ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Constants' for Theta2022 dataset, computed inside ThetaDarshanCompositeLogs notebook (Artefact A_1)\n",
    "m_mean = 0.9985043721898039 \n",
    "non0_percentile75__bf = 23931362.014779434   # Value after filtering on original dataset\n",
    "non0_percentile25__bf = 3162775.2197486456   # Value after filtering on original dataset\n",
    "\n",
    "def compute_b(p0):\n",
    "    x0, y0 = p0[0], p0[1]\n",
    "    b = y0 / ((x0)**m_mean)\n",
    "    return b\n",
    "\n",
    "def computeCategory(io_volume, io_duration, job_id):\n",
    "    \"\"\" Output the category a job is in (2-fast ; 1-regular ; 0-slow) \n",
    "        based on its I/O volume and time spent in I/O\"\"\"\n",
    "    b_job = compute_b((io_duration, io_volume))\n",
    "    category = None\n",
    "    if b_job >= non0_percentile75__bf:\n",
    "        category = 2\n",
    "    elif (b_job < non0_percentile75__bf) & (b_job >= non0_percentile25__bf):\n",
    "        category = 1\n",
    "    elif b_job < non0_percentile25__bf:\n",
    "        category = 0\n",
    "        \n",
    "    if (category == None):\n",
    "        print(f\"ERROR for job {job_id} -> b_job = {b_job} (io_volume = {io_volume} and io_duration = {io_duration}\")\n",
    "    \n",
    "    return category\n",
    "\n",
    "def cohend(data1: list, data2: list):\n",
    "    \"\"\"Compute a Cohen's d metric of two list of values\"\"\"\n",
    "    n_data1, n_data2 = len(data1), len(data2)\n",
    "    var1, var2 = np.var(data1, ddof=1), np.var(data2, ddof=1)\n",
    "    global_var = np.sqrt(\n",
    "        ((n_data1 - 1) * var1 + (n_data2 - 1) * var2) / (n_data1 + n_data2 - 2)\n",
    "    )\n",
    "    mean1, mean2 = np.mean(data1), np.mean(data2)\n",
    "    return (mean1 - mean2) / global_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5144686-076d-499f-aff8-ccba8f22f445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "months = {\"month_nb\": [], \"corr\": []}\n",
    "read_months = {\"month_nb\": [], \"corr\": []}\n",
    "write_months = {\"month_nb\": [], \"corr\": []}\n",
    "job_count_months = {\"month_nb\": [], \"value\": []}\n",
    "cohen = {\"month_nb\": [], \"value\": []}\n",
    "\n",
    "for i in range(1, 13):\n",
    "    \n",
    "    with open(f\"./{RES_DIR}/analysis_month{i}_cat{VALID_CAT}/{EXP_UID}_month{i}_metrics.yaml\", \"r\", encoding=\"utf-8\") as analysis:\n",
    "        metrics = yaml.load(analysis, Loader=yaml.SafeLoader)\n",
    "        # print(metrics)\n",
    "        months[\"month_nb\"].append(i)\n",
    "        months[\"corr\"].append(metrics[\"iotime_correlation\"])\n",
    "        read_months[\"month_nb\"].append(i)\n",
    "        read_months[\"corr\"].append(metrics[\"iotime_read_correlation\"])\n",
    "        write_months[\"month_nb\"].append(i)\n",
    "        write_months[\"corr\"].append(metrics[\"iotime_write_correlation\"])\n",
    "        job_count_months[\"month_nb\"].append(i)\n",
    "        job_count_months[\"value\"].append(metrics[\"job_count\"])\n",
    "        cohen[\"month_nb\"].append(i)\n",
    "        cohen[\"value\"].append(metrics[\"iovolume_cohend_effect\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "620e6ee2-720d-4454-ab07-d039e3a5f5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare stats values per month\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "months[\"row_index\"] = []\n",
    "months[\"col_index\"] = []\n",
    "read_months[\"row_index\"] = []\n",
    "read_months[\"col_index\"] = []\n",
    "write_months[\"row_index\"] = []\n",
    "write_months[\"col_index\"] = []\n",
    "job_count_months[\"row_index\"] = []\n",
    "job_count_months[\"col_index\"] = []\n",
    "cohen[\"row_index\"] = []\n",
    "cohen[\"col_index\"] = []\n",
    "\n",
    "col = 0\n",
    "for i in range(0, 12):\n",
    "    if i % 4 == 0:\n",
    "        col += 1\n",
    "    months[\"row_index\"].append(i % 4  + 1)\n",
    "    months[\"col_index\"].append(col)\n",
    "    read_months[\"row_index\"].append(i % 4 + 1)\n",
    "    read_months[\"col_index\"].append(col)\n",
    "    write_months[\"row_index\"].append(i % 4 + 1)\n",
    "    write_months[\"col_index\"].append(col)\n",
    "    job_count_months[\"row_index\"].append(i % 4 + 1)\n",
    "    job_count_months[\"col_index\"].append(col)\n",
    "    cohen[\"row_index\"].append(i % 4 + 1)\n",
    "    cohen[\"col_index\"].append(col)\n",
    "\n",
    "\n",
    "pd_months = pd.DataFrame(months)\n",
    "pmonths = (\n",
    "    pd_months\n",
    "    .pivot(index=\"col_index\", columns=\"row_index\", values=\"corr\")\n",
    ")\n",
    "\n",
    "pd_Readmonths = pd.DataFrame(read_months)\n",
    "read_pmonths = (\n",
    "    pd_Readmonths\n",
    "    .pivot(index=\"col_index\", columns=\"row_index\", values=\"corr\")\n",
    ")\n",
    "\n",
    "pd_Writemonths = pd.DataFrame(write_months)\n",
    "write_pmonths = (\n",
    "    pd_Writemonths\n",
    "    .pivot(index=\"col_index\", columns=\"row_index\", values=\"corr\")\n",
    ")\n",
    "\n",
    "\n",
    "pd_JCmonths = pd.DataFrame(job_count_months)\n",
    "JC_pmonths = (\n",
    "    pd_JCmonths\n",
    "    .pivot(index=\"col_index\", columns=\"row_index\", values=\"value\")\n",
    ")\n",
    "\n",
    "pd_Cohenmonths = pd.DataFrame(cohen)\n",
    "pd_Cohenmonths = (\n",
    "    pd_Cohenmonths\n",
    "    .pivot(index=\"col_index\", columns=\"row_index\", values=\"value\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80751bac-58c8-46e7-a7e4-538323542211",
   "metadata": {},
   "source": [
    "## Job count per month in the calibration category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2d5ac81-747e-4153-9a50-93a9f38c516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(9, 3))\n",
    "g = sns.heatmap(JC_pmonths, annot=True, fmt=\"d\", linewidths=.5, cmap=\"viridis\", ax=ax)\n",
    "g.set_title(f\"Job count per month (calibration {ID})\")\n",
    "g.set(xlabel=\"\", ylabel=\"\")\n",
    "g.set(xticklabels=[], yticklabels=[])\n",
    "\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_jobCountPerMonth.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba19a4-66c3-4f7f-b036-f19c84d84a12",
   "metadata": {},
   "source": [
    "## Global I/O time correlation between simulation and real traces (R/W I/O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c5771c-c9e0-497d-9275-525761c19d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(9, 3))\n",
    "\n",
    "g = sns.heatmap(pmonths, annot=True, fmt=\".2f\", linewidths=.5, cmap=\"crest\", ax=ax)\n",
    "g.set_title(f\"R/W Correlation (calibration {ID})\")\n",
    "g.set(xlabel=\"\", ylabel=\"\")\n",
    "g.set(xticklabels=[], yticklabels=[])\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_rwCorrMonth.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1458f398-3c7f-4534-b710-c267d74e5d14",
   "metadata": {},
   "source": [
    "## Read I/O time correlation between simulation and real traces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "108e2792-8528-42af-a8e9-1f55f111580e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(9, 3))\n",
    "g = sns.heatmap(read_pmonths, annot=True, fmt=\".2f\", linewidths=.5, cmap=\"crest\",ax=ax)\n",
    "g.set_title(f\"Read Correlation (calibration {ID})\")\n",
    "g.set(xlabel=\"\", ylabel=\"\")\n",
    "g.set(xticklabels=[], yticklabels=[])\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_readCorrMonth.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c7496-01dc-4235-bf4e-2456481fc2b6",
   "metadata": {},
   "source": [
    "## Write I/O time correlation between simulation and real traces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6256fbab-f7a8-4d0b-a849-fc29ac76c925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(9, 3))\n",
    "g = sns.heatmap(write_pmonths, annot=True, fmt=\".2f\", linewidths=.5, cmap=\"crest\",ax=ax)\n",
    "g.set_title(f\"Write Correlation (calibration {ID})\")\n",
    "g.set(xlabel=\"\", ylabel=\"\")\n",
    "g.set(xticklabels=[], yticklabels=[])\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_writeCorrMonth.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1412f425-e285-42c9-bd0d-68b23e6c0f8a",
   "metadata": {},
   "source": [
    "## Simulated vs real cumulative I/O time, per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a9a6914-5399-4754-ab95-0098aa06b569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(24, 12)})\n",
    "\n",
    "gridspec = {\"hspace\":0.4}\n",
    "figure, axis = plt.subplots(3, 4, gridspec_kw=gridspec)\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "month_nb = 0\n",
    "\n",
    "\n",
    "for i in range(1, 13):\n",
    "    \n",
    "    with open(f\"./{RES_DIR}/simulatedJobs_theta2022_aggMonth{i}_cat{VALID_CAT}__Fives_C_theta2022_aggMonth11_cat{CALIB_CAT}_0.0.1_month{i}.yml\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "        results = yaml.load(job_results, Loader=yaml.CLoader)\n",
    "\n",
    "    # Mean diffs\n",
    "    sim_io_time = []\n",
    "    sim_read_time = []\n",
    "    sim_write_time = []\n",
    "    real_io_time = []\n",
    "    real_read_time = []\n",
    "    real_write_time = []\n",
    "\n",
    "    for job in results:\n",
    "\n",
    "        # Simulated\n",
    "        s_io_time = 0\n",
    "        s_r_time = 0\n",
    "        s_w_time = 0\n",
    "        for action in job[\"actions\"]:\n",
    "            if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "                continue\n",
    "            if action[\"act_status\"] != \"COMPLETED\":\n",
    "                continue\n",
    "            if action[\"act_type\"] == \"FILEREAD\":\n",
    "                s_r_time += (action[\"act_duration\"]  + overhead_read) * action[\"nb_stripes\"] \n",
    "            if action[\"act_type\"] == \"CUSTOM\" and \"write\" in str(action[\"sub_job\"]):\n",
    "                s_w_time += (action[\"act_duration\"]  + overhead_write) * action[\"nb_stripes\"]\n",
    "\n",
    "        if len(job['actions']) != 0:\n",
    "            # \"Real\"\n",
    "            r_io_time = ( job[\"real_cReadTime_s\"] \n",
    "                        + job[\"real_cWriteTime_s\"])\n",
    "            real_io_time.append(r_io_time)\n",
    "            real_read_time.append(job[\"real_cReadTime_s\"])\n",
    "            real_write_time.append(job[\"real_cWriteTime_s\"])\n",
    "\n",
    "            s_io_time = (s_r_time + s_w_time)\n",
    "\n",
    "            sim_io_time.append(s_io_time)\n",
    "            sim_read_time.append(s_r_time)\n",
    "            sim_write_time.append(s_w_time)\n",
    "        else:\n",
    "            print(f\"Job {job['job_id']} has 0 actions\") \n",
    "            \n",
    "            \n",
    "    max_target = max(max(real_io_time), max(sim_io_time))\n",
    "    line = {\"x\": [0, max_target], \"y\": [0, max_target]}\n",
    "\n",
    "    scatter = sns.scatterplot(\n",
    "        x=real_io_time, \n",
    "        y=sim_io_time, \n",
    "        s=40, \n",
    "        color=\".15\", \n",
    "        alpha=0.5, \n",
    "        ax=axis[row, col],\n",
    "        label=\"Read/Write\")\n",
    "    read_scatter = sns.scatterplot(\n",
    "        x=real_read_time, y=sim_read_time, s=20, ax=axis[row, col], facecolors=\"red\", marker=\"+\", alpha=0.6, label=\"read\")\n",
    "    write_scatter = sns.scatterplot(\n",
    "        x=real_write_time, y=sim_write_time, s=20, color=\".10\", ax=axis[row, col], facecolors=\"blue\", marker=\"x\", alpha=0.3, label=\"write\")\n",
    "    target_line = sns.lineplot(\n",
    "        line, x=\"x\", y=\"y\", color=\"red\", linestyle=\"--\", ax=axis[row, col], label=\"Real == Sim target\")\n",
    "    scatter.set(xlabel=\"Real\", ylabel=\"Simulated\")\n",
    "    scatter.set(title=f\"Month {month_nb + 1}\")\n",
    "    # axis[row, col].legend()\n",
    "    axis[row, col].set_xscale('log')\n",
    "    axis[row, col].set_xlim([0.0001, max_target*1.05])\n",
    "    axis[row, col].set_yscale('log')\n",
    "    axis[row, col].set_ylim([0.0001, max_target*1.05])\n",
    "\n",
    "    \n",
    "    if col == 3:\n",
    "        row += 1 \n",
    "    col = (col + 1) % 4\n",
    "    month_nb += 1\n",
    "\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_simToRealIotimes.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8198a941-166e-48ad-8d2c-82fb7f017600",
   "metadata": {},
   "source": [
    "## Figure 7 - Calibration dataset - Simulated vs real cumulative I/O time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20064ada-7a52-471d-95de-ae165d1dbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12, 12)})\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Mean diffs\n",
    "sim_io_time = []\n",
    "sim_read_time = []\n",
    "sim_write_time = []\n",
    "real_io_time = []\n",
    "real_read_time = []\n",
    "real_write_time = []\n",
    "\n",
    "calib_month = 11\n",
    "\n",
    "with open(f\"./{RES_DIR}/simulatedJobs_theta2022_aggMonth{calib_month}_cat{VALID_CAT}__Fives_C_theta2022_aggMonth11_cat{CALIB_CAT}_0.0.1_month{calib_month}.yml\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "    results = yaml.load(job_results, Loader=yaml.CLoader)\n",
    "\n",
    "for job in results:\n",
    "\n",
    "    # Simulated\n",
    "    s_io_time = 0\n",
    "    s_r_time = 0\n",
    "    s_w_time = 0\n",
    "    for action in job[\"actions\"]:\n",
    "        if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "            continue\n",
    "        if action[\"act_status\"] != \"COMPLETED\":\n",
    "            continue\n",
    "        if action[\"act_type\"] == \"FILEREAD\":\n",
    "            s_r_time += (action[\"act_duration\"]  + overhead_read) * action[\"nb_stripes\"] \n",
    "        if action[\"act_type\"] == \"CUSTOM\" and \"write\" in str(action[\"sub_job\"]):\n",
    "            s_w_time += (action[\"act_duration\"]  + overhead_write) * action[\"nb_stripes\"]\n",
    "\n",
    "    if len(job['actions']) != 0:\n",
    "        # \"Real\"\n",
    "        r_io_time = ( job[\"real_cReadTime_s\"] \n",
    "                    + job[\"real_cWriteTime_s\"])\n",
    "        real_io_time.append(r_io_time)\n",
    "        real_read_time.append(job[\"real_cReadTime_s\"])\n",
    "        real_write_time.append(job[\"real_cWriteTime_s\"])\n",
    "\n",
    "        s_io_time = (s_r_time + s_w_time)\n",
    "\n",
    "        sim_io_time.append(s_io_time)\n",
    "        sim_read_time.append(s_r_time)\n",
    "        sim_write_time.append(s_w_time)\n",
    "    else:\n",
    "        print(f\"Job {job['job_id']} has 0 actions\") \n",
    "            \n",
    "number_of_jobs = len(real_io_time)       \n",
    "max_target = max(max(real_io_time), max(sim_io_time))\n",
    "min_target = min(min(real_io_time), min(sim_io_time))\n",
    "line = {\"x\": [0, max_target], \"y\": [0, max_target]}\n",
    "\n",
    "scatter = sns.scatterplot(\n",
    "    x=real_io_time, \n",
    "    y=sim_io_time, \n",
    "    s=800, \n",
    "    color=\".15\", \n",
    "    alpha=0.5, \n",
    "    label=\"Jobs\",\n",
    "    zorder=20,\n",
    ")\n",
    "#read_scatter = sns.scatterplot(\n",
    "    #x=real_read_time, y=sim_read_time, s=20, facecolors=\"red\", marker=\"+\", alpha=0.6, label=\"read\")\n",
    "#write_scatter = sns.scatterplot(\n",
    "    #x=real_write_time, y=sim_write_time, s=20, color=\".10\", facecolors=\"blue\", marker=\"x\", alpha=0.3, label=\"write\")\n",
    "target_line = sns.lineplot(\n",
    "    line, x=\"x\", y=\"y\", color=\"red\", linestyle=\"--\", label=\"Sim. I/O == Real I/O target\", linewidth=3.5, zorder=10)\n",
    "scatter.set_xlabel(\"Cumul. Real I/O Time (s)\", fontsize=26)\n",
    "scatter.set_ylabel(\"Cumul. Simulated I/O Time (s)\", fontsize=26)\n",
    "# scatter.axes.set_title(f\"Full year 2019 - {number_of_jobs} jobs (after filtering)\", fontsize=24)\n",
    "scatter.tick_params(labelsize=26)\n",
    "plt.legend(fontsize='26')\n",
    "scatter.set_xscale('log')\n",
    "scatter.set_xlim([min_target, max_target*1.1])\n",
    "scatter.set_yscale('log')\n",
    "scatter.set_ylim([min_target, max_target*1.1])\n",
    "# scatter.minorticks_on()\n",
    "scatter.grid(visible=True, which=\"both\", axis=\"both\", zorder=-10.0, alpha=0.4, linewidth=1)\n",
    "scatter.set_frame_on(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_simToRealIotimes_fcalibrationMonth.pdf\", dpi=300)\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_simToRealIotimes_fcalibrationMonth.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d62cbae-cc33-4f69-b4a3-b6035e059bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12, 12)})\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from scipy.stats import pearsonr, ttest_rel, wilcoxon\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Mean diffs\n",
    "sim_io_time_cat1 = []\n",
    "sim_read_time = []\n",
    "sim_write_time = []\n",
    "real_io_time_cat1 = []\n",
    "real_read_time = []\n",
    "real_write_time = []\n",
    "cat1_jobs = []\n",
    "\n",
    "for i in range(1, 13):\n",
    "    \n",
    "    with open(f\"./{RES_DIR}/simulatedJobs_theta2022_aggMonth{i}_cat{VALID_CAT}__Fives_C_theta2022_aggMonth11_cat{CALIB_CAT}_0.0.1_month{i}.yml\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "        results = yaml.load(job_results, Loader=yaml.CLoader)\n",
    "\n",
    "    for job in results:\n",
    "\n",
    "        #if job[\"job_uid\"] in cursed_jobs:\n",
    "        #    continue\n",
    "\n",
    "        cat1_jobs.append(job[\"job_uid\"])\n",
    "        \n",
    "        # Simulated\n",
    "        s_io_time = 0\n",
    "        s_r_time = 0\n",
    "        s_w_time = 0\n",
    "        for action in job[\"actions\"]:\n",
    "            if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "                continue\n",
    "            if action[\"act_status\"] != \"COMPLETED\":\n",
    "                continue\n",
    "            if action[\"act_type\"] == \"FILEREAD\":\n",
    "                s_r_time += (action[\"act_duration\"]  + overhead_read) * action[\"nb_stripes\"] \n",
    "            if action[\"act_type\"] == \"CUSTOM\" and \"write\" in str(action[\"sub_job\"]):\n",
    "                s_w_time += (action[\"act_duration\"]  + overhead_write) * action[\"nb_stripes\"]\n",
    "\n",
    "        if len(job['actions']) != 0:\n",
    "            # \"Real\"\n",
    "            r_io_time = ( job[\"real_cReadTime_s\"] \n",
    "                        + job[\"real_cWriteTime_s\"])\n",
    "            real_io_time_cat1.append(r_io_time)\n",
    "            real_read_time.append(job[\"real_cReadTime_s\"])\n",
    "            real_write_time.append(job[\"real_cWriteTime_s\"])\n",
    "\n",
    "            s_io_time = (s_r_time + s_w_time)\n",
    "\n",
    "            sim_io_time_cat1.append(s_io_time)\n",
    "            sim_read_time.append(s_r_time)\n",
    "            sim_write_time.append(s_w_time)\n",
    "        else:\n",
    "            print(f\"Job {job['job_id']} has 0 actions\") \n",
    "\n",
    "io_time_corr_cat1, _ = pearsonr(sim_io_time_cat1, real_io_time_cat1)\n",
    "print(f\"Global correlation CAT 1: {io_time_corr_cat1}\")\n",
    "            \n",
    "number_of_jobs = len(real_io_time_cat1)       \n",
    "max_target = max(max(real_io_time_cat1), max(sim_io_time_cat1))\n",
    "min_target = min(min(real_io_time_cat1), min(sim_io_time_cat1))\n",
    "line = {\"x\": [0, max_target], \"y\": [0, max_target]}\n",
    "\n",
    "scatter = sns.scatterplot(\n",
    "    x=real_io_time_cat1, \n",
    "    y=sim_io_time_cat1, \n",
    "    s=180, \n",
    "    color=\".15\", \n",
    "    alpha=0.5, \n",
    "    label=\"Jobs\",\n",
    "    zorder=20,\n",
    ")\n",
    "#read_scatter = sns.scatterplot(\n",
    "    #x=real_read_time, y=sim_read_time, s=20, facecolors=\"red\", marker=\"+\", alpha=0.6, label=\"read\")\n",
    "#write_scatter = sns.scatterplot(\n",
    "    #x=real_write_time, y=sim_write_time, s=20, color=\".10\", facecolors=\"blue\", marker=\"x\", alpha=0.3, label=\"write\")\n",
    "target_line = sns.lineplot(\n",
    "    line, x=\"x\", y=\"y\", color=\"red\", linestyle=\"--\", label=\"Sim. I/O == Real I/O target\", linewidth=3.5, zorder=10)\n",
    "scatter.set_xlabel(\"Cumulated real I/O Time (s)\", fontsize=24)\n",
    "scatter.set_ylabel(\"Cumulated simulated I/O Time (s)\", fontsize=24)\n",
    "# scatter.axes.set_title(f\"Full year 2019 - {number_of_jobs} jobs (after filtering)\", fontsize=24)\n",
    "scatter.tick_params(labelsize=20)\n",
    "plt.legend(fontsize='26')\n",
    "scatter.set_xscale('log')\n",
    "scatter.set_xlim([min_target, max_target*1.05])\n",
    "scatter.set_yscale('log')\n",
    "scatter.set_ylim([min_target, max_target*1.05])\n",
    "scatter.minorticks_on()\n",
    "scatter.grid(visible=True, which=\"both\", axis=\"both\", zorder=-10.0, alpha=0.4, linewidth=1)\n",
    "scatter.set_frame_on(False)\n",
    "\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_simToRealIotimes_fullYearCat{VALID_CAT}.pdf\", dpi=300)\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_simToRealIotimes_fullYearCat{VALID_CAT}.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a716e148-ad40-4682-abbd-c151400ff690",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12, 12)})\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from scipy.stats import pearsonr, ttest_rel, wilcoxon\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Mean diffs\n",
    "sim_io_time_cat1 = []\n",
    "sim_read_time = []\n",
    "sim_write_time = []\n",
    "real_io_time_cat1 = []\n",
    "real_read_time = []\n",
    "real_write_time = []\n",
    "cat1_jobs = []\n",
    "\n",
    "for i in range(1, 13):\n",
    "\n",
    "    if i == 11:\n",
    "        continue\n",
    "    \n",
    "    with open(f\"./{RES_DIR}/simulatedJobs_theta2022_aggMonth{i}_cat{VALID_CAT}__Fives_C_theta2022_aggMonth11_cat{CALIB_CAT}_0.0.1_month{i}.yml\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "        results = yaml.load(job_results, Loader=yaml.CLoader)\n",
    "\n",
    "    for job in results:\n",
    "\n",
    "        #if job[\"job_uid\"] in cursed_jobs:\n",
    "        #    continue\n",
    "\n",
    "        cat1_jobs.append(job[\"job_uid\"])\n",
    "        \n",
    "        # Simulated\n",
    "        s_io_time = 0\n",
    "        s_r_time = 0\n",
    "        s_w_time = 0\n",
    "        for action in job[\"actions\"]:\n",
    "            if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "                continue\n",
    "            if action[\"act_status\"] != \"COMPLETED\":\n",
    "                continue\n",
    "            if action[\"act_type\"] == \"FILEREAD\":\n",
    "                s_r_time += (action[\"act_duration\"]  + overhead_read) * action[\"nb_stripes\"] \n",
    "            if action[\"act_type\"] == \"CUSTOM\" and \"write\" in str(action[\"sub_job\"]):\n",
    "                s_w_time += (action[\"act_duration\"]  + overhead_write) * action[\"nb_stripes\"]\n",
    "\n",
    "        if len(job['actions']) != 0:\n",
    "            # \"Real\"\n",
    "            r_io_time = ( job[\"real_cReadTime_s\"] \n",
    "                        + job[\"real_cWriteTime_s\"])\n",
    "            real_io_time_cat1.append(r_io_time)\n",
    "            real_read_time.append(job[\"real_cReadTime_s\"])\n",
    "            real_write_time.append(job[\"real_cWriteTime_s\"])\n",
    "\n",
    "            s_io_time = (s_r_time + s_w_time)\n",
    "\n",
    "            sim_io_time_cat1.append(s_io_time)\n",
    "            sim_read_time.append(s_r_time)\n",
    "            sim_write_time.append(s_w_time)\n",
    "        else:\n",
    "            print(f\"Job {job['job_id']} has 0 actions\") \n",
    "\n",
    "io_time_corr_cat1, _ = pearsonr(sim_io_time_cat1, real_io_time_cat1)\n",
    "print(f\"Global correlation CAT 1: {io_time_corr_cat1}\")\n",
    "            \n",
    "number_of_jobs = len(real_io_time_cat1)       \n",
    "max_target = max(max(real_io_time_cat1), max(sim_io_time_cat1))\n",
    "min_target = min(min(real_io_time_cat1), min(sim_io_time_cat1))\n",
    "line = {\"x\": [0, max_target], \"y\": [0, max_target]}\n",
    "\n",
    "scatter = sns.scatterplot(\n",
    "    x=real_io_time_cat1, \n",
    "    y=sim_io_time_cat1, \n",
    "    s=180, \n",
    "    color=\".15\", \n",
    "    alpha=0.5, \n",
    "    label=\"Jobs\",\n",
    "    zorder=20,\n",
    ")\n",
    "#read_scatter = sns.scatterplot(\n",
    "    #x=real_read_time, y=sim_read_time, s=20, facecolors=\"red\", marker=\"+\", alpha=0.6, label=\"read\")\n",
    "#write_scatter = sns.scatterplot(\n",
    "    #x=real_write_time, y=sim_write_time, s=20, color=\".10\", facecolors=\"blue\", marker=\"x\", alpha=0.3, label=\"write\")\n",
    "target_line = sns.lineplot(\n",
    "    line, x=\"x\", y=\"y\", color=\"red\", linestyle=\"--\", label=\"Sim. I/O == Real I/O target\", linewidth=3.5, zorder=10)\n",
    "scatter.set_xlabel(\"Cumulated real I/O Time (s)\", fontsize=24)\n",
    "scatter.set_ylabel(\"Cumulated simulated I/O Time (s)\", fontsize=24)\n",
    "# scatter.axes.set_title(f\"Full year 2019 - {number_of_jobs} jobs (after filtering)\", fontsize=24)\n",
    "scatter.tick_params(labelsize=20)\n",
    "plt.legend(fontsize='26')\n",
    "scatter.set_xscale('log')\n",
    "scatter.set_xlim([min_target, max_target*1.05])\n",
    "scatter.set_yscale('log')\n",
    "scatter.set_ylim([min_target, max_target*1.05])\n",
    "scatter.minorticks_on()\n",
    "scatter.grid(visible=True, which=\"both\", axis=\"both\", zorder=-10.0, alpha=0.4, linewidth=1)\n",
    "scatter.set_frame_on(False)\n",
    "\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_simToRealIotimes_fullYearCat{VALID_CAT}_noTrainSet.pdf\", dpi=300)\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_simToRealIotimes_fullYearCat{VALID_CAT}_noTrainSet.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd37c5b1-6388-4c9c-8e9a-a293d1c8df5a",
   "metadata": {},
   "source": [
    "## Figure 9 - Entire year, all job cat. - Simulated vs real cumulative I/O time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "065889a3-cf0b-456e-ac74-478a116dc1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12, 12), 'figure.dpi':300})\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import matplotlib as mpl\n",
    "import yaml\n",
    "\n",
    "fig = mpl.pyplot.Figure()\n",
    "ax = fig.get_axes()\n",
    "\n",
    "with open(f\"{RES_DIR}/simulatedJobs_theta2022_aggMonth11_cat1__Fives_C_theta2022_aggMonth11_cat1_0.0.1_month11.yml\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "    november = yaml.load(job_results, Loader=yaml.CLoader)\n",
    "november_id = set()\n",
    "for job in november:\n",
    "    november_id.add(job[\"job_uid\"])\n",
    "\n",
    "cat_files = [\n",
    "    f\"{RES_DIR}/simulatedJobs_theta2022_0__Fives_C_theta2022_aggMonth11_cat1_0.0.1_p955.yml\",\n",
    "    f\"{RES_DIR}/simulatedJobs_theta2022_1__Fives_C_theta2022_aggMonth11_cat1_0.0.1_p955.yml\",\n",
    "    \"months_657/simulatedJobs_theta2022_2__Fives_C_theta2022_aggMonth10_cat2_0.0.1_657C2.yml\",\n",
    "]\n",
    "\n",
    "r_oh = [overhead_read, overhead_read, 1]\n",
    "w_oh = [overhead_write, overhead_write, 3]\n",
    "\n",
    "colors = [\n",
    "    \"#196A9F\",\n",
    "    \"#464B4F\",\n",
    "    \"#C42626\",\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    \"Slow jobs\",\n",
    "    \"Regular jobs\",\n",
    "    \"Fast jobs\",\n",
    "]\n",
    "\n",
    "markers = [\n",
    "    \"X\",\n",
    "    \"o\",\n",
    "    \"P\",\n",
    "]\n",
    "\n",
    "for cat, file in enumerate(cat_files):\n",
    "    \n",
    "    # Mean diffs\n",
    "    sim_io_time = []\n",
    "    sim_read_time = []\n",
    "    sim_write_time = []\n",
    "    real_io_time = []\n",
    "    real_read_time = []\n",
    "    real_write_time = []\n",
    "    \n",
    "    with open(f\"./{file}\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "        results = yaml.load(job_results, Loader=yaml.CLoader)\n",
    "    \n",
    "    for job in results:\n",
    "\n",
    "        \n",
    "        if job[\"job_uid\"] in november_id:\n",
    "            continue\n",
    "            \n",
    "        # Simulated\n",
    "        s_io_time = 0\n",
    "        s_r_time = 0\n",
    "        s_w_time = 0\n",
    "        for action in job[\"actions\"]:\n",
    "            if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "                continue\n",
    "            if action[\"act_status\"] != \"COMPLETED\":\n",
    "                continue\n",
    "            if action[\"act_type\"] == \"FILEREAD\":\n",
    "                s_r_time += (action[\"act_duration\"]  + r_oh[cat]) * action[\"nb_stripes\"] \n",
    "            if action[\"act_type\"] == \"CUSTOM\" and \"write\" in str(action[\"sub_job\"]):\n",
    "                s_w_time += (action[\"act_duration\"]  + w_oh[cat]) * action[\"nb_stripes\"]\n",
    "    \n",
    "        if len(job['actions']) != 0:\n",
    "            # \"Real\"\n",
    "            r_io_time = ( job[\"real_cReadTime_s\"] \n",
    "                        + job[\"real_cWriteTime_s\"])\n",
    "            real_io_time.append(r_io_time)\n",
    "            real_read_time.append(job[\"real_cReadTime_s\"])\n",
    "            real_write_time.append(job[\"real_cWriteTime_s\"])\n",
    "    \n",
    "            s_io_time = (s_r_time + s_w_time)\n",
    "    \n",
    "            sim_io_time.append(s_io_time)\n",
    "            sim_read_time.append(s_r_time)\n",
    "            sim_write_time.append(s_w_time)\n",
    "        else:\n",
    "            print(f\"Job {job['job_id']} has 0 actions\") \n",
    "                \n",
    "    number_of_jobs = len(real_io_time)       \n",
    "    print(f\"{number_of_jobs} jobs plotted\")\n",
    "    max_target = max(max(real_io_time), max(sim_io_time))\n",
    "    min_target = min(min(real_io_time), min(sim_io_time))\n",
    "    line = {\"x\": [0, max_target], \"y\": [0, max_target]}\n",
    "    \n",
    "    io_time_corr, _ = pearsonr(sim_io_time, real_io_time)\n",
    "    print(f\"Global correlation cat {cat}: {io_time_corr}\")\n",
    "    \n",
    "    scatter = sns.scatterplot(\n",
    "        x=real_io_time, \n",
    "        y=sim_io_time, \n",
    "        s=125, \n",
    "        c=colors[cat],\n",
    "        alpha=0.5, \n",
    "        label=labels[cat],\n",
    "        zorder=10,\n",
    "        marker=markers[cat],\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "target_line = sns.lineplot(\n",
    "    line, x=\"x\", y=\"y\", color=\"red\", linestyle=\"--\", label=\"Sim. I/O == Real I/O target\", linewidth=3.5, zorder=-10)\n",
    "scatter.set_xlabel(\"Cumulated real I/O Time (s)\", fontsize=24)\n",
    "scatter.set_ylabel(\"Cumulated simulated I/O Time (s)\", fontsize=24)\n",
    "scatter.tick_params(labelsize=20)\n",
    "scatter.set_xscale('log')\n",
    "scatter.set_xlim([min_target, max_target*1.05])\n",
    "scatter.set_yscale('log')\n",
    "scatter.set_ylim([min_target, max_target*1.05])\n",
    "# scatter.minorticks_on()\n",
    "scatter.grid(visible=True, which=\"both\", axis=\"both\", zorder=-10.0, alpha=0.4, linewidth=1)\n",
    "scatter.set_frame_on(False)\n",
    "\n",
    "rect = mpl.patches.Rectangle(\n",
    "    xy=(1000, 50000), \n",
    "    width=3000, \n",
    "    height=350000, \n",
    "    alpha=1, \n",
    "    edgecolor=\"black\", \n",
    "    fill=False, \n",
    "    linewidth=2,\n",
    "    clip_on=False,\n",
    "    zorder=50,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "target_line.axes.add_artist(rect)\n",
    "\n",
    "\n",
    "plt.legend(fontsize='20')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_simToRealIotimes_fullYearAllCat.pdf\", dpi=300)\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_simToRealIotimes_fullYearAllCat.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa1cb2e3-b2fe-4c8b-88b6-bf6dba2af213",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12, 12), 'figure.dpi':300})\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import matplotlib as mpl\n",
    "import yaml\n",
    "\n",
    "fig = mpl.pyplot.Figure()\n",
    "ax = fig.get_axes()\n",
    "\n",
    "with open(f\"{RES_DIR}/simulatedJobs_theta2022_aggMonth11_cat1__Fives_C_theta2022_aggMonth11_cat1_0.0.1_month11.yml\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "    november = yaml.load(job_results, Loader=yaml.CLoader)\n",
    "november_id = set()\n",
    "for job in november:\n",
    "    november_id.add(job[\"job_uid\"])\n",
    "\n",
    "cat_files = [\n",
    "    f\"{RES_DIR}/simulatedJobs_theta2022_0__Fives_C_theta2022_aggMonth11_cat1_0.0.1_p955.yml\",\n",
    "    f\"{RES_DIR}/simulatedJobs_theta2022_1__Fives_C_theta2022_aggMonth11_cat1_0.0.1_p955.yml\",\n",
    "    \"months_657/simulatedJobs_theta2022_2__Fives_C_theta2022_aggMonth10_cat2_0.0.1_657C2.yml\",\n",
    "]\n",
    "\n",
    "r_oh = [overhead_read, overhead_read, 1]\n",
    "w_oh = [overhead_write, overhead_write, 3]\n",
    "\n",
    "colors = [\n",
    "    \"#196A9F\",\n",
    "    \"#464B4F\",\n",
    "    \"#C42626\",\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    \"Slow jobs\",\n",
    "    \"Regular jobs\",\n",
    "    \"Fast jobs\",\n",
    "]\n",
    "\n",
    "markers = [\n",
    "    \"X\",\n",
    "    \"o\",\n",
    "    \"P\",\n",
    "]\n",
    "\n",
    "for cat, file in enumerate(cat_files):\n",
    "    \n",
    "    # Mean diffs\n",
    "    sim_io_time = []\n",
    "    sim_read_time = []\n",
    "    sim_write_time = []\n",
    "    real_io_time = []\n",
    "    real_read_time = []\n",
    "    real_write_time = []\n",
    "    \n",
    "    with open(f\"./{file}\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "        results = yaml.load(job_results, Loader=yaml.CLoader)\n",
    "    \n",
    "    for job in results:\n",
    "\n",
    "        \n",
    "        if job[\"job_uid\"] in november_id:\n",
    "            continue\n",
    "            \n",
    "        # Simulated\n",
    "        s_io_time = 0\n",
    "        s_r_time = 0\n",
    "        s_w_time = 0\n",
    "        for action in job[\"actions\"]:\n",
    "            if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "                continue\n",
    "            if action[\"act_status\"] != \"COMPLETED\":\n",
    "                continue\n",
    "            if action[\"act_type\"] == \"FILEREAD\":\n",
    "                s_r_time += (action[\"act_duration\"]  + r_oh[cat]) * action[\"nb_stripes\"] \n",
    "            if action[\"act_type\"] == \"CUSTOM\" and \"write\" in str(action[\"sub_job\"]):\n",
    "                s_w_time += (action[\"act_duration\"]  + w_oh[cat]) * action[\"nb_stripes\"]\n",
    "    \n",
    "        if len(job['actions']) != 0:\n",
    "            # \"Real\"\n",
    "            r_io_time = ( job[\"real_cReadTime_s\"] \n",
    "                        + job[\"real_cWriteTime_s\"])\n",
    "            real_io_time.append(r_io_time)\n",
    "            real_read_time.append(job[\"real_cReadTime_s\"])\n",
    "            real_write_time.append(job[\"real_cWriteTime_s\"])\n",
    "    \n",
    "            s_io_time = (s_r_time + s_w_time)\n",
    "    \n",
    "            sim_io_time.append(s_io_time)\n",
    "            sim_read_time.append(s_r_time)\n",
    "            sim_write_time.append(s_w_time)\n",
    "        else:\n",
    "            print(f\"Job {job['job_id']} has 0 actions\") \n",
    "                \n",
    "    number_of_jobs = len(real_io_time)       \n",
    "    print(f\"{number_of_jobs} jobs plotted\")\n",
    "    max_target = max(max(real_io_time), max(sim_io_time))\n",
    "    min_target = min(min(real_io_time), min(sim_io_time))\n",
    "    line = {\"x\": [0, max_target], \"y\": [0, max_target]}\n",
    "    \n",
    "    io_time_corr, _ = pearsonr(sim_io_time, real_io_time)\n",
    "    print(f\"Global correlation cat {cat}: {io_time_corr}\")\n",
    "    \n",
    "    scatter = sns.scatterplot(\n",
    "        x=real_io_time, \n",
    "        y=sim_io_time, \n",
    "        s=125, \n",
    "        c=colors[cat],\n",
    "        alpha=0.5, \n",
    "        label=labels[cat],\n",
    "        zorder=10,\n",
    "        marker=markers[cat],\n",
    "    )\n",
    "\n",
    "    target_line = sns.lineplot(\n",
    "        line, x=\"x\", y=\"y\", color=\"red\", linestyle=\"--\", label=\"Sim. I/O == Real I/O target\", linewidth=3.5, zorder=-10)\n",
    "    scatter.set_xlabel(\"Cumulated real I/O Time (s)\", fontsize=40)\n",
    "    scatter.set_ylabel(\"Cumulated simulated I/O Time (s)\", fontsize=40)\n",
    "    scatter.tick_params(labelsize=32)\n",
    "    scatter.set_xscale('log')\n",
    "    scatter.set_xlim([min_target, max_target*1.05])\n",
    "    scatter.set_yscale('log')\n",
    "    scatter.set_ylim([min_target, max_target*1.05])\n",
    "    # scatter.minorticks_on()\n",
    "    scatter.grid(visible=True, which=\"both\", axis=\"both\", zorder=-10.0, alpha=0.4, linewidth=1)\n",
    "    scatter.set_frame_on(False)\n",
    "\n",
    "    if cat == 1:\n",
    "        rect = mpl.patches.Rectangle(\n",
    "            xy=(1000, 50000), \n",
    "            width=3000, \n",
    "            height=350000, \n",
    "            alpha=1, \n",
    "            edgecolor=\"black\", \n",
    "            fill=False, \n",
    "            linewidth=2,\n",
    "            clip_on=False,\n",
    "            zorder=50,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "        target_line.axes.add_artist(rect)\n",
    "\n",
    "    plt.legend(fontsize='36')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RES_DIR}/{ID}_simToRealIotimes_fullYearAllCat{cat}.pdf\", dpi=300)\n",
    "    plt.savefig(f\"{RES_DIR}/{ID}_simToRealIotimes_fullYearAllCat{cat}.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f513b39f-8287-41b7-b320-f71b3eecf735",
   "metadata": {},
   "source": [
    "## I/O volume over I/O duration (simulated, per month and per job category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3f84536-6dcc-44af-b376-0af189924ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from yaml import load, CLoader\n",
    "import pathlib\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12, 12)})\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "directory = f\"./{RES_DIR}\"\n",
    "\n",
    "result_path = pathlib.Path(directory)\n",
    "files = [f for f in result_path.iterdir() if f.is_file()]\n",
    "files = sorted(files)\n",
    "files = [file for file in files if (\"simulatedJobs\" in str(file) and \"p955\" not in str(file))]\n",
    "\n",
    "for idx, filename in enumerate(files):\n",
    "\n",
    "    sim_io_times = np.array([])\n",
    "    sim_io_volumes = np.array([])\n",
    "    sim_io_bw_mb = np.array([])\n",
    "    \n",
    "    out_of_class = 0\n",
    "    \n",
    "    results = None\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as job_results:\n",
    "        results = load(job_results, Loader=CLoader)\n",
    "    \n",
    "    for job in results:\n",
    "\n",
    "        # Simulated only\n",
    "        s_io_time = 0\n",
    "        s_r_time = 0\n",
    "        s_w_time = 0\n",
    "        s_io_vol = 0\n",
    "        for action in job[\"actions\"]:\n",
    "            if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "                continue\n",
    "            if action[\"act_status\"] != \"COMPLETED\":\n",
    "                continue\n",
    "            if action[\"act_type\"] == \"FILEREAD\":\n",
    "                s_io_time += (action[\"act_duration\"] + overhead_read)* action[\"nb_stripes\"] \n",
    "                s_io_vol += action[\"io_size_bytes\"]\n",
    "            if action[\"act_type\"] == \"CUSTOM\" and \"write\" in str(action[\"sub_job\"]):\n",
    "                s_io_time += (action[\"act_duration\"] + overhead_write)* action[\"nb_stripes\"] \n",
    "                s_io_vol += action[\"io_size_bytes\"] \n",
    "\n",
    "        if len(job['actions']) != 0:\n",
    "            sim_io_times = np.append(sim_io_times, s_io_time)\n",
    "            sim_io_volumes = np.append(sim_io_volumes, s_io_vol)\n",
    "            sim_io_bw_mb = np.append(sim_io_bw_mb, (s_io_vol / 1_000_000) / s_io_time)\n",
    "            \n",
    "        sim_category = computeCategory(s_io_vol, s_io_time, job['job_uid'])\n",
    "        if int(sim_category) != int(job[\"category\"]):\n",
    "            out_of_class += 1\n",
    "            # print(f\"Sim category {sim_category} != real category {job['category']}\")\n",
    "                \n",
    "    print(f\"Jobs out of their class : {out_of_class} / {len(results)}\")\n",
    "    print(f\"({(out_of_class * 100) / len(results)} % out of class)\")\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,5), frameon=True, linewidth=0, layout='constrained')\n",
    "\n",
    "    # Scatter plot of Total IO time to Total Bytes READ\n",
    "    g = sns.scatterplot(x=sim_io_times, y=sim_io_volumes, palette=sns.color_palette(\"crest\", as_cmap=True), hue=sim_io_bw_mb, ax=ax, zorder=10)\n",
    "    g.set(xscale='log', yscale='log')\n",
    "    g.set(xlabel=\"Total simulated I/O duration per job (s)\", ylabel=\"Total simulated I/O volume per job (Bytes)\")\n",
    "    month= str(filename)[str(filename).rfind(\"_\")+1:-4] # Diirtttyy\n",
    "    g.set(title=month)\n",
    "\n",
    "    line_75_f = {'x': [0.1, 1000000.0], 'y': [2401391.9159769486, 23441945375976.598]}\n",
    "    line_25_f = {'x': [0.1, 1000000.0], 'y': [317368.59941636777, 3098093785554.3726]}\n",
    "    sns.lineplot(x=\"x\", y=\"y\", data=line_75_f, legend=None, color=\"#e91140\", zorder=20, label=\"Q3 I/O BW Filtered\", ax=ax, linestyle=\"-\", linewidth=1, alpha=0.8)\n",
    "    sns.lineplot(x=\"x\", y=\"y\", data=line_25_f, legend=None, color=\"#2b54a5\", zorder=20, label=\"Q1 I/O BW Filtered\", ax=ax, linestyle=\"-\", linewidth=1, alpha=0.8)\n",
    "    \n",
    "    ax.minorticks_on()\n",
    "    ax.grid(visible=True, which=\"both\", axis=\"both\", zorder=-10.0, alpha=0.4, linewidth=1)\n",
    "    ax.set_frame_on(False)\n",
    "    # ax.set_xlim(10e-5)\n",
    "\n",
    "    legend = ax.legend(loc=\"best\", bbox_to_anchor=(1, 0.5, 0, 0.4), fontsize=10, frameon=False, handletextpad=0.2)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles.insert(-2, handles[0])\n",
    "    labels.insert(-2, \"Bandwidth\\nthresholds\")\n",
    "\n",
    "    legend._legend_box = None\n",
    "    legend._init_legend_box(handles, labels)\n",
    "    legend._set_loc(legend._loc)\n",
    "    legend.set_title(legend.get_title().get_text())\n",
    "\n",
    "    texts = legend.get_texts()\n",
    "    for text in texts:\n",
    "        if text.get_text() == \"CUMUL_READ_BW_MB\":\n",
    "            text.set_text(\"Cumulated read\\nbandwidth\")\n",
    "        if text.get_text() == \"NODES_USED\":\n",
    "            text.set_text(\"Nodes in\\nreservation\")\n",
    "            break\n",
    "        try:\n",
    "            int(text.get_text())\n",
    "        except ValueError:\n",
    "            continue\n",
    "        else:\n",
    "            text.set_text(f\"<= {int(text.get_text())} MB/s\")\n",
    "\n",
    "    plt.savefig(f\"{RES_DIR}/{ID}_IOVolumeToTime_Simulated_{month}.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aca9e926-00f2-42f6-aba7-a2e8649f32c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from yaml import load, CLoader\n",
    "import pathlib\n",
    "\n",
    "directory = f\"./{RES_DIR}\"\n",
    "\n",
    "result_path = pathlib.Path(directory)\n",
    "files = [f for f in result_path.iterdir() if f.is_file()]\n",
    "files = sorted(files)\n",
    "files = [file for file in files if \"p955\" in str(file)]\n",
    "\n",
    "for idx, filename in enumerate(files):\n",
    "\n",
    "    sim_io_times = np.array([])\n",
    "    sim_io_volumes = np.array([])\n",
    "    sim_io_bw_mb = np.array([])\n",
    "    \n",
    "    out_of_class = 0\n",
    "    \n",
    "    results = None\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as job_results:\n",
    "        results = load(job_results, Loader=CLoader)\n",
    "    \n",
    "    for job in results:\n",
    "\n",
    "        # Simulated only\n",
    "        s_io_time = 0\n",
    "        s_r_time = 0\n",
    "        s_w_time = 0\n",
    "        s_io_vol = 0\n",
    "        for action in job[\"actions\"]:\n",
    "            if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "                continue\n",
    "            if action[\"act_status\"] != \"COMPLETED\":\n",
    "                continue\n",
    "            if action[\"act_type\"] == \"FILEREAD\":\n",
    "                s_io_time += (action[\"act_duration\"] + overhead_read) *action[\"nb_stripes\"] \n",
    "                s_io_vol += action[\"io_size_bytes\"]\n",
    "            if action[\"act_type\"] == \"CUSTOM\" and \"write\" in str(action[\"sub_job\"]):\n",
    "                s_io_time += (action[\"act_duration\"] + overhead_write) * action[\"nb_stripes\"] \n",
    "                s_io_vol += action[\"io_size_bytes\"] \n",
    "\n",
    "        if len(job['actions']) != 0:\n",
    "            sim_io_times = np.append(sim_io_times, s_io_time)\n",
    "            sim_io_volumes = np.append(sim_io_volumes, s_io_vol)\n",
    "            sim_io_bw_mb = np.append(sim_io_bw_mb, (s_io_vol / 1_000_000) / s_io_time)\n",
    "            \n",
    "        sim_category = computeCategory(s_io_vol, s_io_time, job['job_uid'])\n",
    "        if int(sim_category) != int(job[\"category\"]):\n",
    "            out_of_class += 1\n",
    "            # print(f\"Sim category {sim_category} != real category {job['category']}\")\n",
    "                \n",
    "    print(f\"Jobs out of their class : {out_of_class} / {len(results)}\")\n",
    "\n",
    "    line_75 = {'x': [0.1, 1000000.0], 'y': [5071992.807945422, 49511859168074.27]}\n",
    "    line_25 = {'x': [0.1, 1000000.0], 'y': [242675.1002595881, 2368949610659.6855]}\n",
    "    line_75_f = {'x': [0.1, 1000000.0], 'y': [2401391.9159769486, 23441945375976.598]}\n",
    "    line_25_f = {'x': [0.1, 1000000.0], 'y': [317368.59941636777, 3098093785554.3726]}\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,5), frameon=True, linewidth=0, layout='constrained')\n",
    "\n",
    "    # Scatter plot of Total IO time to Total Bytes READ\n",
    "    g = sns.scatterplot(x=sim_io_times, y=sim_io_volumes, palette=sns.color_palette(\"crest\", as_cmap=True), hue=sim_io_bw_mb, ax=ax, zorder=10)\n",
    "    g.set(xscale='log', yscale='log')\n",
    "    g.set(xlabel=\"Total simulated I/O duration per job (s)\", ylabel=\"Total simulated I/O volume per job (Bytes)\")\n",
    "    pos = str(filename).find(\"theta2022_\")\n",
    "    title = str(filename)[pos + 10:str(filename).find(\"_\", pos + 12)] # Diirtttyy\n",
    "    print(title)\n",
    "    g.set(title=title)\n",
    "\n",
    "    sns.lineplot(x=\"x\", y=\"y\", data=line_75_f, legend=None, color=\"#e91140\", zorder=20, label=\"Q3 I/O BW Filtered\", ax=ax, linestyle=\"-\", linewidth=1, alpha=0.8)\n",
    "    sns.lineplot(x=\"x\", y=\"y\", data=line_25_f, legend=None, color=\"#2b54a5\", zorder=20, label=\"Q1 I/O BW Filtered\", ax=ax, linestyle=\"-\", linewidth=1, alpha=0.8)\n",
    "\n",
    "    \n",
    "    ax.minorticks_on()\n",
    "    ax.grid(visible=True, which=\"both\", axis=\"both\", zorder=-10.0, alpha=0.4, linewidth=1)\n",
    "    ax.set_frame_on(False)\n",
    "    # ax.set_xlim(10e-5)\n",
    "\n",
    "    legend = ax.legend(loc=\"best\", bbox_to_anchor=(1, 0.5, 0, 0.4), fontsize=10, frameon=False, handletextpad=0.2)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles.insert(-2, handles[0])\n",
    "    labels.insert(-2, \"Bandwidth\\nthresholds\")\n",
    "\n",
    "    legend._legend_box = None\n",
    "    legend._init_legend_box(handles, labels)\n",
    "    legend._set_loc(legend._loc)\n",
    "    legend.set_title(legend.get_title().get_text())\n",
    "\n",
    "    texts = legend.get_texts()\n",
    "    for text in texts:\n",
    "        if text.get_text() == \"CUMUL_READ_BW_MB\":\n",
    "            text.set_text(\"Cumulated read\\nbandwidth\")\n",
    "        if text.get_text() == \"NODES_USED\":\n",
    "            text.set_text(\"Nodes in\\nreservation\")\n",
    "            break\n",
    "        try:\n",
    "            int(text.get_text())\n",
    "        except ValueError:\n",
    "            continue\n",
    "        else:\n",
    "            text.set_text(f\"<= {int(text.get_text())} MB/s\")\n",
    "\n",
    "    plt.savefig(f\"{RES_DIR}/{ID}_IOVolumeToTime_Simulated_{title}.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f6b10-29ed-4bf3-99ff-f7d78d2abb16",
   "metadata": {},
   "source": [
    "## Figure 7 (legacy) - I/O volume over I/O duration - Simulation vs traces comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea9d73f2-88c8-47b9-88f1-b2b689d26108",
   "metadata": {},
   "outputs": [],
   "source": [
    "### REAL PART\n",
    "import numpy as np\n",
    "from yaml import load, CLoader\n",
    "import pathlib\n",
    "import matplotlib as mpl\n",
    "\n",
    "with open(f\"../exp_datasets/theta2022_aggMonth11_cat1.yaml\", \"r\", encoding=\"utf-8\") as job_dataset:\n",
    "    dataset = yaml.load(job_dataset, Loader=yaml.CLoader)\n",
    "\n",
    "out_of_class = 0 \n",
    "\n",
    "real_io_time = []\n",
    "real_read_time = []\n",
    "real_write_time = []\n",
    "\n",
    "real_jobs = {\"io_vol_bytes\": [], \"io_time_s\": []}\n",
    "\n",
    "for job in dataset[\"jobs\"]:\n",
    "\n",
    "    sum_io_volume = job[\"readBytes\"] + job[\"writtenBytes\"] \n",
    "    sum_io_time =  job[\"readTimeSeconds\"] + job[\"writeTimeSeconds\"] + job[\"metaTimeSeconds\"]\n",
    "    real_jobs[\"io_vol_bytes\"].append(sum_io_volume)\n",
    "    real_jobs[\"io_time_s\"].append(sum_io_time)\n",
    "\n",
    "## SIMULATION PART\n",
    "results = None\n",
    "with open(f\"./{RES_DIR}/simulatedJobs_theta2022_aggMonth11_cat1__Fives_C_theta2022_aggMonth11_cat1_0.0.1_month11.yml\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "    results = load(job_results, Loader=CLoader)\n",
    "\n",
    "sim_io_times = np.array([])\n",
    "sim_io_volumes = np.array([])\n",
    "sim_io_bw_mb = np.array([])\n",
    "\n",
    "for job in results:\n",
    "    \n",
    "    s_io_time = 0\n",
    "    s_r_time = 0\n",
    "    s_w_time = 0\n",
    "    s_io_vol = 0\n",
    "    for action in job[\"actions\"]:\n",
    "        if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "            continue\n",
    "        if action[\"act_status\"] != \"COMPLETED\":\n",
    "            continue\n",
    "        if action[\"act_type\"] == \"FILEREAD\":\n",
    "            s_io_time += (action[\"act_duration\"] + overhead_read)* action[\"nb_stripes\"] \n",
    "            s_io_vol += action[\"io_size_bytes\"]\n",
    "        if action[\"act_type\"] == \"CUSTOM\" and \"write\" in str(action[\"sub_job\"]):\n",
    "            s_io_time += (action[\"act_duration\"] + overhead_write)* action[\"nb_stripes\"] \n",
    "            s_io_vol += action[\"io_size_bytes\"] \n",
    "\n",
    "    if len(job['actions']) != 0:\n",
    "        sim_io_times = np.append(sim_io_times, s_io_time)\n",
    "        sim_io_volumes = np.append(sim_io_volumes, s_io_vol)\n",
    "        sim_io_bw_mb = np.append(sim_io_bw_mb, (s_io_vol / 1_000_000) / s_io_time)\n",
    "        \n",
    "    sim_category = computeCategory(s_io_vol, s_io_time, job['job_uid'])\n",
    "    if int(sim_category) != int(job[\"category\"]):\n",
    "        out_of_class += 1\n",
    "\n",
    "line_75_f = {'x': [0.1, 1000000.0], 'y': [2401391.9159769486, 23441945375976.598]}\n",
    "line_25_f = {'x': [0.1, 1000000.0], 'y': [317368.59941636777, 3098093785554.3726]}\n",
    "x_min = min(min(real_jobs[\"io_time_s\"]), min(sim_io_times))\n",
    "x_max = max(max(real_jobs[\"io_time_s\"]), max(sim_io_times))\n",
    "y_min = min(min(real_jobs[\"io_vol_bytes\"]), min(sim_io_volumes))\n",
    "y_max = max(max(real_jobs[\"io_vol_bytes\"]), max(sim_io_volumes))\n",
    "\n",
    "# Scatter plot of Total IO time to Total Bytes READ\n",
    "g = sns.scatterplot(x=real_jobs[\"io_time_s\"], y=real_jobs[\"io_vol_bytes\"], color=\"green\", zorder=10, alpha=0.4, s=800, label=\"Real\")\n",
    "g.set_xlabel(\"Cumul. IO time (R/W Sec. from all processes)\", fontsize=26)\n",
    "g.set_ylabel(\"Cumul. IO volume (R/W Bytes from all processes)\", fontsize=26)\n",
    "g.set(xscale='log', yscale='log')\n",
    "g.tick_params(labelsize=26)\n",
    "plt.legend(fontsize='22')\n",
    "g.set_xscale('log')\n",
    "g.set_yscale('log')\n",
    "g.set_xlim([x_min*0.90, x_max*1.15])\n",
    "g.set_ylim([y_min*0.90, y_max*1.15])\n",
    "#g.minorticks_on()\n",
    "g.grid(visible=True, which=\"both\", axis=\"both\", zorder=-10.0, alpha=0.4, linewidth=1)\n",
    "g.set_frame_on(False)\n",
    "\n",
    "g2 = sns.scatterplot(x=sim_io_times, y=sim_io_volumes, color='orange', alpha=0.4, zorder=10, s=800,label=\"Simulated\")\n",
    "\n",
    "sns.lineplot(x=\"x\", y=\"y\", data=line_75_f, legend=None, color=\"#e91140\", zorder=-20, label=\"Q3 I/O BW Filtered\", linestyle=\"-\", linewidth=2, alpha=0.8)\n",
    "sns.lineplot(x=\"x\", y=\"y\", data=line_25_f, legend=None, color=\"#2b54a5\", zorder=-20, label=\"Q1 I/O BW Filtered\", linestyle=\"-\", linewidth=2, alpha=0.8)\n",
    "plt.legend(fontsize='26')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_volumeToTime_realVSsim_month11.png\", dpi=300)\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_volumeToTime_realVSsim_month11.pdf\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Out of class : {out_of_class}\")\n",
    "tt_job_count = len(results)\n",
    "print(f\"Total number of jobs: {tt_job_count}\")\n",
    "print(f\"%tage of simulated jobs IN rightfull class: {(tt_job_count - out_of_class) / (tt_job_count) * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc9afc0-20d8-42b3-986f-daad6f28599c",
   "metadata": {},
   "source": [
    "### Figure 7 HiPC Paper (Cumulative I/O volume vs. I/O time for real (green) and simulated (grey) regular jobs. Year of 2022, excl. training set (November).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7e336e3-a767-4057-9d46-bc4955239fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "import numpy as np\n",
    "from yaml import load, CLoader\n",
    "import pathlib\n",
    "import matplotlib as mpl\n",
    "\n",
    "with open(f\"{RES_DIR}/simulatedJobs_theta2022_aggMonth11_cat1__Fives_C_theta2022_aggMonth11_cat1_0.0.1_month11.yml\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "    november = load(job_results, Loader=CLoader)\n",
    "november_id = set()\n",
    "for job in november:\n",
    "    november_id.add(job[\"job_uid\"])\n",
    "\n",
    "### REAL PART\n",
    "with open(f\"../exp_datasets/theta2022_1.yaml\", \"r\", encoding=\"utf-8\") as job_dataset:\n",
    "    dataset = yaml.load(job_dataset, Loader=yaml.CLoader)\n",
    "\n",
    "dataset_without_november = {'jobs': []}\n",
    "for job in dataset['jobs']:\n",
    "    if job['id'] not in november_id:\n",
    "        dataset_without_november['jobs'].append(job)\n",
    "        \n",
    "out_of_class = 0 \n",
    "\n",
    "real_io_time = []\n",
    "real_read_time = []\n",
    "real_write_time = []\n",
    "real_jobs = {\"io_vol_bytes\": [], \"io_time_s\": []}\n",
    "\n",
    "for job in dataset_without_november[\"jobs\"]:\n",
    "    sum_io_volume = job[\"readBytes\"] + job[\"writtenBytes\"] \n",
    "    sum_io_time =  job[\"readTimeSeconds\"] + job[\"writeTimeSeconds\"] + job[\"metaTimeSeconds\"]\n",
    "    real_jobs[\"io_vol_bytes\"].append(sum_io_volume)\n",
    "    real_jobs[\"io_time_s\"].append(sum_io_time)\n",
    "\n",
    "## SIMULATION PART\n",
    "results = None\n",
    "with open(f\"{RES_DIR}/simulatedJobs_theta2022_1__Fives_C_theta2022_aggMonth11_cat1_0.0.1_p955.yml\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "    results = load(job_results, Loader=CLoader)\n",
    "\n",
    "sim_io_times = np.array([])\n",
    "sim_io_volumes = np.array([])\n",
    "sim_io_bw_mb = np.array([])\n",
    "\n",
    "for job in results:\n",
    "\n",
    "    if job[\"job_uid\"] in november_id:\n",
    "        continue\n",
    "    \n",
    "    s_io_time = 0\n",
    "    s_r_time = 0\n",
    "    s_w_time = 0\n",
    "    s_io_vol = 0\n",
    "    for action in job[\"actions\"]:\n",
    "        if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "            continue\n",
    "        if action[\"act_status\"] != \"COMPLETED\":\n",
    "            continue\n",
    "        if action[\"act_type\"] == \"FILEREAD\":\n",
    "            s_io_time += (action[\"act_duration\"] + overhead_read)* action[\"nb_stripes\"] \n",
    "            s_io_vol += action[\"io_size_bytes\"]\n",
    "        if action[\"act_type\"] == \"CUSTOM\" and \"write\" in str(action[\"sub_job\"]):\n",
    "            s_io_time += (action[\"act_duration\"] + overhead_write)* action[\"nb_stripes\"] \n",
    "            s_io_vol += action[\"io_size_bytes\"] \n",
    "\n",
    "    if len(job['actions']) != 0:\n",
    "        sim_io_times = np.append(sim_io_times, s_io_time)\n",
    "        sim_io_volumes = np.append(sim_io_volumes, s_io_vol)\n",
    "        sim_io_bw_mb = np.append(sim_io_bw_mb, (s_io_vol / 1_000_000) / s_io_time)\n",
    "        \n",
    "    sim_category = computeCategory(s_io_vol, s_io_time, job['job_uid'])\n",
    "    if int(sim_category) != int(job[\"category\"]):\n",
    "        out_of_class += 1\n",
    "\n",
    "    \n",
    "line_75_f = {'x': [0.1, 1000000.0], 'y': [2401391.9159769486, 23441945375976.598]}\n",
    "line_25_f = {'x': [0.1, 1000000.0], 'y': [317368.59941636777, 3098093785554.3726]}\n",
    "\n",
    "x_min = min(min(real_jobs[\"io_time_s\"]), min(sim_io_times))\n",
    "x_max = max(max(real_jobs[\"io_time_s\"]), max(sim_io_times))\n",
    "y_min = min(min(real_jobs[\"io_vol_bytes\"]), min(sim_io_volumes))\n",
    "y_max = max(max(real_jobs[\"io_vol_bytes\"]), max(sim_io_volumes))\n",
    "\n",
    "# Scatter plot of Total IO time to Total Bytes READ\n",
    "g = sns.scatterplot(x=real_jobs[\"io_time_s\"], y=real_jobs[\"io_vol_bytes\"], color=\"green\", zorder=10, alpha=0.4, s=150, label=\"Real\")\n",
    "g.set_xlabel(\"Cumul. IO time (R/W Sec. from all processes)\", fontsize=26)\n",
    "g.set_ylabel(\"Cumul. IO volume (R/W Bytes from all processes)\", fontsize=26)\n",
    "g.set(xscale='log', yscale='log')\n",
    "g.tick_params(labelsize=26)\n",
    "plt.legend(fontsize='22')\n",
    "g.set_xscale('log')\n",
    "g.set_yscale('log')\n",
    "g.set_xlim([x_min*0.90, x_max*1.15])\n",
    "g.set_ylim([y_min*0.90, y_max*1.15])\n",
    "#g.minorticks_on()\n",
    "g.grid(visible=True, which=\"both\", axis=\"both\", zorder=-10.0, alpha=0.4, linewidth=1)\n",
    "g.set_frame_on(False)\n",
    "\n",
    "g2 = sns.scatterplot(x=sim_io_times, y=sim_io_volumes, color='orange', alpha=0.4, zorder=10, s=150,label=\"Simulated\", marker=\"v\")\n",
    "\n",
    "sns.lineplot(x=\"x\", y=\"y\", data=line_75_f, legend=None, color=\"#e91140\", zorder=-20, label=\"Q3 I/O BW Filtered\", linestyle=\"-\", linewidth=3, alpha=0.8)\n",
    "sns.lineplot(x=\"x\", y=\"y\", data=line_25_f, legend=None, color=\"#2b54a5\", zorder=-20, label=\"Q1 I/O BW Filtered\", linestyle=\"-\", linewidth=3, alpha=0.8)\n",
    "plt.legend(fontsize='26')\n",
    "\n",
    "rect = mpl.patches.Rectangle(\n",
    "    xy=(45000, 2.5e11), \n",
    "    width=2.9e5, \n",
    "    height=0.9e11, \n",
    "    alpha=1, \n",
    "    edgecolor=\"black\", \n",
    "    fill=False, \n",
    "    linewidth=2,\n",
    "    clip_on=False,\n",
    "    zorder=50,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "g2.axes.add_artist(rect)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_volumeToTime_realVSsim_FullYearC1_noTrainSet.png\", dpi=300)\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_volumeToTime_realVSsim_FullYearC1_noTrainSet.pdf\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Out of class : {out_of_class}\")\n",
    "tt_job_count = len(results)\n",
    "print(f\"Total number of jobs: {tt_job_count}\")\n",
    "print(f\"%tage of simulated jobs IN rightfull class: {(tt_job_count - out_of_class) / (tt_job_count) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bf46d4a-1496-4824-835b-b9a49364a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Same as above but with simulated jobs only, and for the 3 classes\n",
    "import numpy as np\n",
    "from yaml import load, CLoader\n",
    "import pathlib\n",
    "import matplotlib as mpl\n",
    "\n",
    "out_of_class_regular = 0\n",
    "out_of_class_slow = 0\n",
    "out_of_class_fast = 0\n",
    "\n",
    "## SIMULATION JOBS, CAT 1\n",
    "results = None\n",
    "with open(f\"{RES_DIR}/simulatedJobs_theta2022_1__Fives_C_theta2022_aggMonth11_cat1_0.0.1_p955.yml\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "    results = load(job_results, Loader=CLoader)\n",
    "\n",
    "sim_io_times_reg = np.array([])\n",
    "sim_io_volumes_reg = np.array([])\n",
    "\n",
    "for job in results:\n",
    "    \n",
    "    s_io_time = 0\n",
    "    s_r_time = 0\n",
    "    s_w_time = 0\n",
    "    s_io_vol = 0\n",
    "    for action in job[\"actions\"]:\n",
    "        if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "            continue\n",
    "        if action[\"act_status\"] != \"COMPLETED\":\n",
    "            continue\n",
    "        if action[\"act_type\"] == \"FILEREAD\":\n",
    "            s_io_time += (action[\"act_duration\"] + overhead_read)* action[\"nb_stripes\"] \n",
    "            s_io_vol += action[\"io_size_bytes\"]\n",
    "        if action[\"act_type\"] == \"CUSTOM\" and \"write\" in str(action[\"sub_job\"]):\n",
    "            s_io_time += (action[\"act_duration\"] + overhead_write)* action[\"nb_stripes\"] \n",
    "            s_io_vol += action[\"io_size_bytes\"] \n",
    "\n",
    "    if len(job['actions']) != 0:\n",
    "        sim_io_times_reg = np.append(sim_io_times, s_io_time)\n",
    "        sim_io_volumes_reg = np.append(sim_io_volumes, s_io_vol)\n",
    "        \n",
    "    sim_category = computeCategory(s_io_vol, s_io_time, job['job_uid'])\n",
    "    if int(sim_category) != int(job[\"category\"]):\n",
    "        out_of_class_regular += 1\n",
    "\n",
    "\n",
    "## SIMULATION JOBS, CAT 2\n",
    "results_fast = None\n",
    "with open(\"months_657/simulatedJobs_theta2022_2__Fives_C_theta2022_aggMonth10_cat2_0.0.1_657C2.yml\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "    results_fast = load(job_results, Loader=CLoader)\n",
    "\n",
    "sim_io_times_fast = np.array([])\n",
    "sim_io_volumes_fast = np.array([])\n",
    "\n",
    "for job in results_fast:\n",
    "    \n",
    "    s_io_time = 0\n",
    "    s_r_time = 0\n",
    "    s_w_time = 0\n",
    "    s_io_vol = 0\n",
    "    for action in job[\"actions\"]:\n",
    "        if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "            continue\n",
    "        if action[\"act_status\"] != \"COMPLETED\":\n",
    "            continue\n",
    "        if action[\"act_type\"] == \"FILEREAD\":\n",
    "            s_io_time += (action[\"act_duration\"] + 1)* action[\"nb_stripes\"] \n",
    "            s_io_vol += action[\"io_size_bytes\"]\n",
    "        if action[\"act_type\"] == \"CUSTOM\" and \"write\" in str(action[\"sub_job\"]):\n",
    "            s_io_time += (action[\"act_duration\"] + 3)* action[\"nb_stripes\"] \n",
    "            s_io_vol += action[\"io_size_bytes\"] \n",
    "\n",
    "    if len(job['actions']) != 0:\n",
    "        sim_io_times_fast = np.append(sim_io_times, s_io_time)\n",
    "        sim_io_volumes_fast = np.append(sim_io_volumes, s_io_vol)\n",
    "        \n",
    "    sim_category = computeCategory(s_io_vol, s_io_time, job['job_uid'])\n",
    "    if int(sim_category) != int(job[\"category\"]):\n",
    "        out_of_class_fast += 1\n",
    "\n",
    "\n",
    "## SIMULATION JOBS, CAT 0\n",
    "results_slow = None\n",
    "with open(f\"{RES_DIR}/simulatedJobs_theta2022_0__Fives_C_theta2022_aggMonth11_cat1_0.0.1_p955.yml\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "    results_slow = load(job_results, Loader=CLoader)\n",
    "\n",
    "sim_io_times_slow = np.array([])\n",
    "sim_io_volumes_slow = np.array([])\n",
    "\n",
    "for job in results_slow:\n",
    "    \n",
    "    s_io_time = 0\n",
    "    s_r_time = 0\n",
    "    s_w_time = 0\n",
    "    s_io_vol = 0\n",
    "    for action in job[\"actions\"]:\n",
    "        if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "            continue\n",
    "        if action[\"act_status\"] != \"COMPLETED\":\n",
    "            continue\n",
    "        if action[\"act_type\"] == \"FILEREAD\":\n",
    "            s_io_time += (action[\"act_duration\"] + overhead_read) * action[\"nb_stripes\"] \n",
    "            s_io_vol += action[\"io_size_bytes\"]\n",
    "        if action[\"act_type\"] == \"CUSTOM\" and \"write\" in str(action[\"sub_job\"]):\n",
    "            s_io_time += (action[\"act_duration\"] + overhead_write) * action[\"nb_stripes\"] \n",
    "            s_io_vol += action[\"io_size_bytes\"] \n",
    "\n",
    "    if len(job['actions']) != 0:\n",
    "        sim_io_times_slow = np.append(sim_io_times, s_io_time)\n",
    "        sim_io_volumes_slow = np.append(sim_io_volumes, s_io_vol)\n",
    "        \n",
    "    sim_category = computeCategory(s_io_vol, s_io_time, job['job_uid'])\n",
    "    if int(sim_category) != int(job[\"category\"]):\n",
    "        out_of_class_slow += 1\n",
    "\n",
    "\n",
    "\n",
    "# Min-max plot bounds\n",
    "x_min = min(min(sim_io_times_reg), min(sim_io_times_fast), min(sim_io_times_slow))\n",
    "x_max = max(max(sim_io_times_reg), max(sim_io_times_fast), max(sim_io_times_fast))\n",
    "y_min = min(min(sim_io_volumes_reg), min(sim_io_volumes_fast), min(sim_io_volumes_slow))\n",
    "y_max = max(max(sim_io_volumes_reg), max(sim_io_volumes_fast), max(sim_io_volumes_fast))\n",
    "\n",
    "# Plot everything\n",
    "\n",
    "# Quartile lines\n",
    "line_75_f = {'x': [0.1, 1000000.0], 'y': [2401391.9159769486, 23441945375976.598]}\n",
    "line_25_f = {'x': [0.1, 1000000.0], 'y': [317368.59941636777, 3098093785554.3726]}\n",
    "sns.lineplot(x=\"x\", y=\"y\", data=line_75_f, legend=None, color=\"#e91140\", zorder=-20, label=\"Q3 I/O BW Filtered\", linestyle=\"-\", linewidth=3, alpha=0.8)\n",
    "sns.lineplot(x=\"x\", y=\"y\", data=line_25_f, legend=None, color=\"#2b54a5\", zorder=-20, label=\"Q1 I/O BW Filtered\", linestyle=\"-\", linewidth=3, alpha=0.8)\n",
    "\n",
    "g = sns.scatterplot(x=sim_io_times_reg, y=sim_io_volumes_reg, color='grey', alpha=0.4, zorder=10, s=150,label=\"Regular\", marker=\"o\")\n",
    "g2 = sns.scatterplot(x=sim_io_times_fast, y=sim_io_volumes_fast, color='red', alpha=0.4, zorder=10, s=150,label=\"Fast\", marker=\"+\")\n",
    "g3 = sns.scatterplot(x=sim_io_times_slow, y=sim_io_volumes_slow, color='blue', alpha=0.4, zorder=10, s=150,label=\"Slow\", marker=\"v\")\n",
    "\n",
    "# Plot Settings\n",
    "plt.legend(fontsize='26')\n",
    "g.set_xlabel(\"Cumul. IO time (R/W Sec. from all processes)\", fontsize=26)\n",
    "g.set_ylabel(\"Cumul. IO volume (R/W Bytes from all processes)\", fontsize=26)\n",
    "g.set(xscale='log', yscale='log')\n",
    "g.tick_params(labelsize=26)\n",
    "g.set_xscale('log')\n",
    "g.set_yscale('log')\n",
    "g.set_xlim([x_min*0.90, x_max*1.15])\n",
    "g.set_ylim([y_min*0.90, y_max*1.15])\n",
    "g.grid(visible=True, which=\"both\", axis=\"both\", zorder=-10.0, alpha=0.4, linewidth=1)\n",
    "g.set_frame_on(False)\n",
    "\n",
    "# Print plot \n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_volumeToTime_realVSsim_FullYearAllCat.png\", dpi=300)\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_volumeToTime_realVSsim_FullYearAllCat.pdf\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Out of class (regular): {out_of_class_regular}\")\n",
    "print(f\"Out of class (fast): {out_of_class_fast}\")\n",
    "print(f\"Out of class (slow): {out_of_class_slow}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5905e2-58f4-441d-afef-9b58a2a15c34",
   "metadata": {},
   "source": [
    "## Figure 10 - Variation of the OST count of the platform, based on calibrated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36b599a3-ab20-41e6-a2a3-1e3a707d7f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12, 12), 'figure.dpi':300})\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import numpy as np\n",
    "from yaml import load, CLoader\n",
    "import pathlib\n",
    "import matplotlib as mpl\n",
    "from  scipy.stats import ttest_rel, ttest_ind\n",
    "\n",
    "ost_files = [\n",
    "    \"ost_count_inc/simulatedJobs_theta2022_aggMonth11_cat1__Fives_C_theta2022_aggMonth11_cat1_0.0.1_955_O7F.yml\",   \n",
    "    \"ost_count_inc/simulatedJobs_theta2022_aggMonth11_cat1__Fives_C_theta2022_aggMonth11_cat1_0.0.1_955_O14F.yml\",    \n",
    "    \"ost_count_inc/simulatedJobs_theta2022_aggMonth11_cat1__Fives_C_theta2022_aggMonth11_cat1_0.0.1_955_O28F.yml\",\n",
    "    \"ost_count_inc/simulatedJobs_theta2022_aggMonth11_cat1__Fives_C_theta2022_aggMonth11_cat1_0.0.1_955_O56F.yml\",\n",
    "    \"ost_count_inc/simulatedJobs_theta2022_aggMonth11_cat1__Fives_C_theta2022_aggMonth11_cat1_0.0.1_955_O84F.yml\",\n",
    "]\n",
    "\n",
    "colors = [\n",
    "    \"#70A9A1\",\n",
    "    \"#EDAE49\",\n",
    "    \"#FF6B6B\",\n",
    "    \"#464B4F\",   # OST =56\n",
    "    \"#8390FA\",\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    \"7\",\n",
    "    \"14\",\n",
    "    \"28\",\n",
    "    \"56\",\n",
    "    \"84\",\n",
    "]\n",
    "\n",
    "all_sim_io_times = []\n",
    "all_sim_io_volumes = []\n",
    "\n",
    "for ost_inc, file in enumerate(ost_files):\n",
    "\n",
    "    sim_io_times = np.array([])\n",
    "    sim_io_volumes = np.array([])\n",
    "\n",
    "    results = None\n",
    "    with open(f\"./{file}\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "        results = load(job_results, Loader=CLoader)\n",
    "    \n",
    "    out_of_class = 0\n",
    "    for job in results:\n",
    "\n",
    "        s_io_time = 0\n",
    "        s_r_time = 0\n",
    "        s_w_time = 0\n",
    "        s_io_vol = 0\n",
    "        for action in job[\"actions\"]:\n",
    "            if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "                continue\n",
    "            if action[\"act_status\"] != \"COMPLETED\":\n",
    "                continue\n",
    "            if action[\"act_type\"] == \"FILEREAD\":\n",
    "                s_io_time += (action[\"act_duration\"] + overhead_read) * action[\"nb_stripes\"] \n",
    "                s_io_vol += action[\"io_size_bytes\"]\n",
    "            if action[\"act_type\"] == \"CUSTOM\" and \"write\" in str(action[\"sub_job\"]):\n",
    "                s_io_time += (action[\"act_duration\"] + overhead_write) * action[\"nb_stripes\"] \n",
    "                s_io_vol += action[\"io_size_bytes\"] \n",
    "    \n",
    "        if len(job['actions']) != 0:\n",
    "            sim_io_times = np.append(sim_io_times, s_io_time)\n",
    "            sim_io_volumes = np.append(sim_io_volumes, s_io_vol)\n",
    "            \n",
    "    x_min = min(sim_io_times)\n",
    "    x_max = max(sim_io_times)\n",
    "    y_min = min(sim_io_volumes)\n",
    "    y_max = max(sim_io_volumes)\n",
    "    \n",
    "    scatter = sns.scatterplot(\n",
    "        x=sim_io_times, \n",
    "        y=sim_io_volumes, \n",
    "        s=800, \n",
    "        c=colors[ost_inc],\n",
    "        alpha=0.8, \n",
    "        label=labels[ost_inc],\n",
    "        zorder=10 * ost_inc,\n",
    "    )\n",
    "    scatter.set_xlabel(\"Cumul. IO time (R/W Sec. from all processes)\", fontsize=26)\n",
    "    scatter.set_ylabel(\"Cumul. IO volume (R/W Bytes from all processes)\", fontsize=26)\n",
    "    scatter.set(xscale='log', yscale='log')\n",
    "    scatter.tick_params(labelsize=26)\n",
    "    scatter.set_xscale('log')\n",
    "    scatter.set_yscale('log')\n",
    "\n",
    "    all_sim_io_times.append(sim_io_times)\n",
    "    all_sim_io_volumes.append(sim_io_volumes)\n",
    "    print(f\"Mean cumulative I/O times for jobs with {labels[ost_inc]} osts: {sim_io_times.mean()}s\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"T test 56 <-> 84 : {ttest_rel(all_sim_io_times[3], all_sim_io_times[4])}\")\n",
    "print(f\"T test 7 <-> 56 : {ttest_ind(all_sim_io_times[0], all_sim_io_times[3])}\")\n",
    "\n",
    "#scatter.set_xlim([x_min*0.80, x_max*1.3])\n",
    "#scatter.set_ylim([y_min*0.80, y_max*1.3])\n",
    "scatter.grid(visible=True, which=\"both\", axis=\"both\", zorder=-10.0, alpha=0.4, linewidth=1)\n",
    "\n",
    "scatter.set_frame_on(False)\n",
    "\n",
    "plt.legend(fontsize='26')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_ostCountInc.pdf\", dpi=300)\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_ostCountInc.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a7698dd-6208-4c26-9286-224ae8c8c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "    \"#70A9A1\",\n",
    "    \"#EDAE49\",\n",
    "    \"#FF6B6B\",\n",
    "    \"#464B4F\",   # OST =56\n",
    "    \"#8390FA\",\n",
    "    \"#ED474A\",\n",
    "    #\"#8390FA\",\n",
    "    #\"#A0C9B1\",\n",
    "]\n",
    "\n",
    "\n",
    "x=[7, 14, 28, 56, 84]\n",
    "y=[35, 24, 10, 0 ,0]\n",
    "\n",
    "bar = sns.barplot(x=x, y=y, hue=x, palette=colors, legend=False)\n",
    "bar.tick_params(labelsize=26)\n",
    "bar.set_title(\"Failed jobs\", fontsize=26)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_ostCountIncFailedJobs.pdf\", dpi=300)\n",
    "plt.savefig(f\"{RES_DIR}/{ID}_ostCountIncFailedJobs.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
