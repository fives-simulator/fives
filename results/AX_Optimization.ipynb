{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2df20a3-bd6a-4638-b6fe-31f5f68ed9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.metrics.branin import branin\n",
    "from ax.utils.measurement.synthetic_functions import hartmann6\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "\n",
    "init_notebook_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05223e4b-df8a-4e30-bed8-f25085f9eceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "\n",
    "# Start from a configuration base for the platform we experiment on\n",
    "CONFIGURATION_BASE = \"./exp_configurations/theta_config.yml\"\n",
    "\n",
    "yaml_config = None\n",
    "\n",
    "with open(CONFIGURATION_BASE, \"r\", encoding=\"utf-8\") as cfg_base:\n",
    "    yaml_config = yaml.load(cfg_base, Loader=yaml.FullLoader)\n",
    "\n",
    "# Remove keys that are only used inside the file with Yaml anchors/aliases\n",
    "del yaml_config[\"storage\"][\"disk_templates\"]\n",
    "del yaml_config[\"storage\"][\"node_templates\"]\n",
    "\n",
    "print(json.dumps(yaml_config, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297d7076-b62e-4f4a-ab23-f643cf6ea84e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the parameters that will be given to Ax for the optimization loop\n",
    "# Bounds / value lists are not final\n",
    "\n",
    "AX_PARAMS = [\n",
    "    {\n",
    "        \"name\": \"backbone_bw\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [220, 240],\n",
    "        \"value_type\": \"int\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"permanent_storage_read_bw\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [5, 90],\n",
    "        \"value_type\": \"int\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"permanent_storage_write_bw\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [5, 90],\n",
    "        \"value_type\": \"int\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"preload_percent\",\n",
    "        \"type\": \"choice\",\n",
    "        \"is_ordered\": True,\n",
    "        \"values\": [0.1, 0.2, 0.3],\n",
    "        \"value_type\": \"float\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"amdahl\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.1, 1.0],\n",
    "        \"value_type\": \"float\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"walltime_extension\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [1.0, 1.3],\n",
    "        \"value_type\": \"float\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"disk_rb\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [600, 6000],\n",
    "        \"value_type\": \"int\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"disk_wb\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [300, 3000],\n",
    "        \"value_type\": \"int\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"stripe_size\",\n",
    "        \"type\": \"choice\",\n",
    "        \"values\": [2097152, 4096000, 131072000, 524288000, 1048576000],\n",
    "        \"is_ordered\": True,\n",
    "        \"value_type\": \"int\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"stripe_count\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [1, 40],   # NOTE : never using all OSTs for any allocatin so far\n",
    "        \"value_type\": \"int\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"non_linear_coef_read\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.2, 1],\n",
    "        \"value_type\": \"float\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"non_linear_coef_write\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.2, 1],\n",
    "        \"value_type\": \"float\",\n",
    "    },\n",
    "        {\n",
    "        \"name\": \"read_variability\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.2, 1],\n",
    "        \"value_type\": \"float\",\n",
    "    },\n",
    "        {\n",
    "        \"name\": \"write_variability\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.2, 1],\n",
    "        \"value_type\": \"float\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea17d03-c276-4e24-a693-294f8b10f061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def cohend(d1, d2):\n",
    "    # calculate the size of samples\n",
    "    n1, n2 = len(d1), len(d2)\n",
    "    # calculate the variance of the samples\n",
    "    s1, s2 = np.var(d1, ddof=1), np.var(d2, ddof=1)\n",
    "    # calculate the pooled standard deviation\n",
    "    s = np.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "    # calculate the means of the samples\n",
    "    u1, u2 = np.mean(d1), np.mean(d2)\n",
    "    # calculate the effect size\n",
    "    return (u1 - u2) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec17997b-fd50-4926-9635-0fc678198b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import threading\n",
    "import subprocess\n",
    "import pathlib\n",
    "\n",
    "DATASET = \"theta2022_week4\"\n",
    "\n",
    "experiment_config_seq_nb = 0;\n",
    "sequence_nb_lock = threading.Lock()\n",
    "\n",
    "def runSimulationWithParam(parametrization):\n",
    "    \n",
    "    backbone_bw = parametrization.get(\"backbone_bw\")\n",
    "    permanent_storage_read_bw = parametrization.get(\"permanent_storage_read_bw\")\n",
    "    permanent_storage_write_bw = parametrization.get(\"permanent_storage_write_bw\")\n",
    "    preload_percent = parametrization.get(\"preload_percent\")\n",
    "    amdahl = parametrization.get(\"amdahl\")\n",
    "    walltime_extension = parametrization.get(\"walltime_extension\")\n",
    "    disk_rb = parametrization.get(\"disk_rb\")\n",
    "    disk_wb = parametrization.get(\"disk_wb\")\n",
    "    stripe_size = parametrization.get(\"stripe_size\")\n",
    "    stripe_count = parametrization.get(\"stripe_count\")\n",
    "    non_linear_coef_read = parametrization.get(\"non_linear_coef_read\")\n",
    "    non_linear_coef_write = parametrization.get(\"non_linear_coef_write\")\n",
    "    read_variability = parametrization.get(\"read_variability\")\n",
    "    write_variability = parametrization.get(\"write_variability\")\n",
    "    \n",
    "    # Update config file according to parameters provided by Ax\n",
    "    \n",
    "    yaml_config[\"general\"][\"backbone_bw\"] = f\"{backbone_bw}GBps\"\n",
    "    yaml_config[\"general\"][\"permanent_storage_read_bw\"] = f\"{permanent_storage_read_bw}GBps\"\n",
    "    yaml_config[\"general\"][\"permanent_storage_write_bw\"] = f\"{permanent_storage_write_bw}GBps\"\n",
    "    yaml_config[\"general\"][\"preload_percent\"] = preload_percent\n",
    "    yaml_config[\"general\"][\"amdahl\"] = amdahl\n",
    "    yaml_config[\"general\"][\"walltime_extension\"] = walltime_extension\n",
    "    yaml_config[\"general\"][\"non_linear_coef_read\"] = non_linear_coef_read\n",
    "    yaml_config[\"general\"][\"non_linear_coef_write\"] = non_linear_coef_write\n",
    "    yaml_config[\"general\"][\"read_variability\"] = read_variability\n",
    "    yaml_config[\"general\"][\"write_variability\"] = write_variability\n",
    "    \n",
    "    # WARINING : HERE WE SET THE SAME READ/WRITE BANDWIDTH FOR ALL DISKS - THIS WILL NOT ALWAYS BE THE CASE.\n",
    "    for storage_node in yaml_config[\"storage\"][\"nodes\"]:\n",
    "        for disk in storage_node[\"template\"][\"disks\"]:\n",
    "            disk[\"template\"][\"read_bw\"] = disk_rb\n",
    "            disk[\"template\"][\"write_bw\"] = disk_wb\n",
    "\n",
    "    yaml_config[\"lustre\"][\"stripe_size\"] = stripe_size\n",
    "    yaml_config[\"lustre\"][\"stripe_count\"] = stripe_count\n",
    "\n",
    "    \n",
    "    # Save config as file with a unique name for each parameter set\n",
    "    global sequence_nb_lock\n",
    "    global experiment_config_seq_nb\n",
    "    \n",
    "    random_part = \"\".join(random.choices([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], k=4))\n",
    "    \n",
    "    sequence_nb_lock.acquire()\n",
    "    output_configuration = f\"./exp_configurations/exp_config_{experiment_config_seq_nb}_{random_part}\"\n",
    "    experiment_config_seq_nb += 1\n",
    "    sequence_nb_lock.release()\n",
    "    \n",
    "    with open(output_configuration, \"w\", encoding=\"utf-8\") as exp_config:\n",
    "        print(\"Dumping configuration to \" + output_configuration)\n",
    "        yaml.dump(yaml_config, exp_config)\n",
    "        \n",
    "    # Now run simulatin with the current configuration file\n",
    "    completed = subprocess.run([\"../build/storalloc_wrench\", output_configuration, f\"../../raw_data_processing/theta/{DATASET}.yaml\", random_part], capture_output=True)\n",
    "    print(f\"Simulation with tag {random_part} has completed with status : {completed.returncode}\")\n",
    "    if completed.returncode != 0:\n",
    "        raise RuntimeError(\"Simulation did not complete\")\n",
    "    \n",
    "    result_filename = f\"simulatedJobs_{DATASET}__{yaml_config['general']['config_name']}_{yaml_config['general']['config_version']}_{random_part}.yml\"\n",
    "    print(f\"Now looking for result file : {result_filename}\")\n",
    "    \n",
    "    result_file = pathlib.Path(f\"./{result_filename}\")\n",
    "    if not result_file.exists() or not result_file.is_file():\n",
    "        raise RuntimeError(f\"Result file {result_filename} was not found\")\n",
    "        \n",
    "    print(result_file.resolve())\n",
    "    move_result = subprocess.run([\"mv\", result_file.resolve(), f\"./exp_results/{result_filename}\"], capture_output=True)\n",
    "    if move_result.returncode != 0:\n",
    "        raise RuntimeError(f\"Result file was not moved correctly\")\n",
    "\n",
    "    # No exploit results\n",
    "    results = None\n",
    "    with open(f\"./exp_results/{result_filename}\", \"r\", encoding=\"utf-8\") as job_results:\n",
    "        results = yaml.load(job_results, Loader=yaml.CLoader)\n",
    "        \n",
    "    # WAIT TIME : \n",
    "    wait_time_diffs = []\n",
    "    sim_wait_time = []\n",
    "    real_wait_time = []\n",
    "    \n",
    "    # RUNTIME\n",
    "    runtime_diffs = []\n",
    "    sim_runtime = []\n",
    "    real_runtime = []\n",
    "    \n",
    "    # IO TIME\n",
    "    io_time_diff = []\n",
    "    sim_io_time = []\n",
    "    sim_read_time = []\n",
    "    sim_write_time = []\n",
    "    real_io_time = []\n",
    "    real_read_time = []\n",
    "    real_write_time = []\n",
    "\n",
    "    for job in results:\n",
    "        # WAIT TIME\n",
    "        wait_time_diffs.append(abs(job[\"job_waiting_time_s\"] - job[\"real_waiting_time_s\"]))\n",
    "        sim_wait_time.append(job[\"job_waiting_time_s\"])\n",
    "        real_wait_time.append(job[\"real_waiting_time_s\"])\n",
    "        # RUNTIME\n",
    "        runtime_diffs.append(abs(job[\"job_runtime_s\"] - job[\"real_runtime_s\"]))\n",
    "        sim_runtime.append(job[\"job_runtime_s\"])\n",
    "        real_runtime.append(job[\"real_runtime_s\"])\n",
    "        \n",
    "        \n",
    "        # IO TIME\n",
    "        r_io_time = (job[\"real_cReadTime_s\"] +  job[\"real_cWriteTime_s\"] +  job[\"real_cMetaTime_s\"]) / job[\"real_cores_used\"]\n",
    "        real_io_time.append(r_io_time)\n",
    "        real_read_time.append(job[\"real_cReadTime_s\"] / job[\"real_cores_used\"])\n",
    "        real_write_time.append(job[\"real_cWriteTime_s\"] / job[\"real_cores_used\"])\n",
    "\n",
    "        s_io_time = 0\n",
    "        s_r_time = 0\n",
    "        s_w_time = 0\n",
    "        for action in job[\"actions\"]:\n",
    "            if action[\"act_type\"] == \"COMPUTE\" or action[\"act_type\"] == \"SLEEP\":\n",
    "                continue\n",
    "            if action[\"act_status\"] != \"COMPLETED\":\n",
    "                continue\n",
    "            if action[\"act_type\"] == \"FILEREAD\":\n",
    "                s_r_time += action[\"act_duration\"]\n",
    "            if action[\"act_type\"] == \"FILEWRITE\":\n",
    "                s_w_time += action[\"act_duration\"]\n",
    "            s_io_time += action[\"act_duration\"]\n",
    "\n",
    "        sim_io_time.append(s_io_time)\n",
    "        sim_read_time.append(s_r_time)\n",
    "        sim_write_time.append(s_w_time)\n",
    "        io_time_diff.append(abs(s_io_time - r_io_time))\n",
    "    \n",
    "    \n",
    "    # Correlations / Cohen's d\n",
    "    \n",
    "    mean_wait_time_difference = np.mean(wait_time_diffs)\n",
    "    # Pearson's correlation\n",
    "    wait_time_corr, _ = pearsonr(sim_wait_time, real_wait_time)\n",
    "    # Cohen's D \n",
    "    wait_time_cohen_d = cohend(sim_wait_time, real_wait_time)\n",
    "    \n",
    "    mean_runtime_difference = np.mean(runtime_diffs)\n",
    "    # Pearson's correlation\n",
    "    runtime_corr, _ = pearsonr(sim_runtime, real_runtime)\n",
    "    # Cohen's D \n",
    "    runtime_cohen_d = cohend(sim_runtime, real_runtime)\n",
    "    \n",
    "    mean_io_time_difference = np.mean(io_time_diff)\n",
    "    # Pearson's correlation\n",
    "    io_time_corr, _ = pearsonr(sim_io_time, real_io_time)\n",
    "    # Cohen's D \n",
    "    io_time_cohen_d = cohend(sim_io_time, real_io_time)\n",
    "    \n",
    "                                                                                                                                                                           # Adding weight to the io_time metric\n",
    "    return {\"optimization_metric\": (abs(1 - runtime_corr) + abs(1 - wait_time_corr) + abs(1 - io_time_corr) + abs(runtime_cohen_d) + abs(wait_time_cohen_d) + abs(io_time_cohen_d))}\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"runtime_corr\": abs(1 - runtime_corr), \"runtime_cohen\": abs(runtime_cohen_d), \n",
    "        \"wait_time_corr\": abs(1 - wait_time_corr), \"wait_time_cohen\": abs(wait_time_cohen_d), \n",
    "        \"io_time_corr\": abs(1 - io_time_corr), \"io_time_cohen\": abs(io_time_cohen_d)\n",
    "    }\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaca218a-5393-40de-8288-bba2b574940f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "from ax.utils.measurement.synthetic_functions import hartmann6\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "\n",
    "ax_client = AxClient()\n",
    "\n",
    "\"\"\"\n",
    "# Multi-objectives version.\n",
    "\"runtime_corr\": ObjectiveProperties(minimize=True, threshold=0.05), \"runtime_cohen\": ObjectiveProperties(minimize=True, threshold=0.05), \n",
    "\"wait_time_corr\": ObjectiveProperties(minimize=True, threshold=0.05), \"wait_time_cohen\": ObjectiveProperties(minimize=True, threshold=0.05), \n",
    "\"io_time_corr\": ObjectiveProperties(minimize=True, threshold=0.05), \"io_time_cohen\": ObjectiveProperties(minimize=True, threshold=0.05)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "ax_client.create_experiment(\n",
    "    name=\"StorallocWrench_ThetaExperiment\",\n",
    "    parameters=AX_PARAMS,\n",
    "    objectives={ \n",
    "        \"optimization_metric\": ObjectiveProperties(minimize=True, threshold=0.2),\n",
    "    },\n",
    "    parameter_constraints=[\"walltime_extension + amdahl >= 1.4\", \"disk_rb >= disk_wb\", \"permanent_storage_read_bw >= permanent_storage_write_bw\"],\n",
    "    outcome_constraints=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76ea4034-a631-4daa-9999-ea541e514f39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(45):\n",
    "    parameters, trial_index = ax_client.get_next_trial()\n",
    "    data = None\n",
    "    try:\n",
    "        data = runSimulationWithParam(parameters)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        ax_client.log_trial_failure(trial_index=trial_index)\n",
    "        continue\n",
    "    else:\n",
    "        ax_client.complete_trial(trial_index=trial_index, raw_data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0e5103a-06a7-4819-b316-46804f1f438a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_parameters, values = ax_client.get_best_parameters()\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1389592-7d35-4d25-b66f-be2e45ebea89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "means, covariances = values\n",
    "means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
